{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7b64f-42fd-4a83-aefe-7d60678c3cf0",
   "metadata": {},
   "source": [
    "Tuesday, June 13, 2023\n",
    "\n",
    "This video shows how to manually implement back propogation in a multi layer perceptron.\n",
    "\n",
    "docker container start sad_nightingale\n",
    "\n",
    "[Building makemore Part 4: Becoming a Backprop Ninja](https://www.youtube.com/watch?v=q8SA3rM6ckI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25e9341-c435-4be5-ac56-0225357b4d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7c8aeb-0294-4ee3-b983-4e161201afb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "lenOfWords = len(words)\n",
    "print(lenOfWords)\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c51f71-77c2-40e7-a827-632a5947e89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3cd2a0-d8e2-4f08-8e00-efd0249d7552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8b147f-c618-47c6-b510-6ee2074aaf00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "stoi[delimiter] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b8f870-e3d5-44cd-a6b9-3f04b75252c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "itos = { c:i for i, c in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fcbb34-7767-4608-8ad7-b7fa04046c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1fed5e-846d-4f9e-af94-8f3a3d5881b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + delimiter:\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a6c897-d864-47ff-bde1-16df400e23ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thgttg = 42\n",
    "manualSeed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aafd307-ad2e-430a-8ad6-c37fff7f3ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(thgttg)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e6995a-ecec-4801-8344-b61f36463ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626 28829\n"
     ]
    }
   ],
   "source": [
    "n1 = int(0.8 * lenOfWords)\n",
    "n2 = int(0.9 * lenOfWords)\n",
    "print(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3ba7b7-0f67-42b0-ae1c-377507dc1dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Ytd = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a285df-b211-4b95-92eb-5cd2cb0f94a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ok boilerplate code is done, now we get to the action ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc684e22-ad13-4116-903e-5acebd5b65f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "all(input) -> Tensor\n",
       "\n",
       "Tests if all elements in :attr:`input` evaluate to `True`.\n",
       "\n",
       ".. note:: This function matches the behaviour of NumPy in returning\n",
       "          output of dtype `bool` for all supported dtypes except `uint8`.\n",
       "          For `uint8` the dtype of output is `uint8` itself.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(1, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[False, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a)\n",
       "    tensor(False, dtype=torch.bool)\n",
       "    >>> a = torch.arange(0, 3)\n",
       "    >>> a\n",
       "    tensor([0, 1, 2])\n",
       "    >>> torch.all(a)\n",
       "    tensor(False)\n",
       "\n",
       ".. function:: all(input, dim, keepdim=False, *, out=None) -> Tensor\n",
       "   :noindex:\n",
       "\n",
       "For each row of :attr:`input` in the given dimension :attr:`dim`,\n",
       "returns `True` if all elements in the row evaluate to `True` and `False` otherwise.\n",
       "\n",
       "If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
       "as :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
       "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
       "the output tensor having 1 fewer dimension than :attr:`input`.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    dim (int): the dimension to reduce.\n",
       "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(4, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[True, True],\n",
       "            [True, False],\n",
       "            [True, True],\n",
       "            [True, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=1)\n",
       "    tensor([ True, False,  True,  True], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=0)\n",
       "    tensor([ True, False], dtype=torch.bool)\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.all??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7c7971-604e-4dd2-a68b-a9d33b4ba034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> bool\n",
       "\n",
       "This function checks if all :attr:`input` and :attr:`other` satisfy the condition:\n",
       "\n",
       ".. math::\n",
       "    \\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n",
       "\n",
       "elementwise, for all elements of :attr:`input` and :attr:`other`. The behaviour of this function is analogous to\n",
       "`numpy.allclose <https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html>`_\n",
       "\n",
       "Args:\n",
       "    input (Tensor): first tensor to compare\n",
       "    other (Tensor): second tensor to compare\n",
       "    atol (float, optional): absolute tolerance. Default: 1e-08\n",
       "    rtol (float, optional): relative tolerance. Default: 1e-05\n",
       "    equal_nan (bool, optional): if ``True``, then two ``NaN`` s will be considered equal. Default: ``False``\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\n",
       "    True\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\n",
       "    True\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.allclose??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "547d57bd-92a1-4d3c-9bf5-b2c7669c81cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function we weill use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate {str(app):5s} | maxdiff {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52b92be0-1a5d-4719-b326-15e1fa06413c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(manualSeed) # for reproducability\n",
    "\n",
    "# the embedding table for the characters ...\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/ ((n_embd * block_size) ** 0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of batch normalization\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# Note: I am initializing many of these parameters in non-standard ways\n",
    "# because sometimes initializing with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd584d9-3904-4556-80fb-23f470f435d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a sorter variable, also for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86e31c48-7070-4f53-bf95-d76a0237d1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.sum??\n",
    "# Docstring:\n",
    "# sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
    "\n",
    "# See :func:`torch.sum`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee09c314-3285-496a-92a5-e8f5db1f84c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 2 + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc54fb01-8129-47a6-abba-7107f7ec0a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.max??\n",
    "# Docstring:\n",
    "# max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
    "\n",
    "# See :func:`torch.max`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a3feb65-ab62-4aec-9500-4516a28deb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3531, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# Batch Normalization Layer\n",
    "bnmeani = 1/n * hprebn.sum(dim=0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(dim=0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-Linearity\n",
    "h = torch.tanh(hpreact)\n",
    "\n",
    "# Linear Layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(dim=1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(dim=1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 # if we use (1.0 / counts_sum) instead then we can't get backprop to be bit exact ... \n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "    \n",
    "# PyTorch retain_grad => Enables this Tensor to have their grad populated during backward(). \n",
    "# This is a no-op for leaf tensors\n",
    "\n",
    "# afaik there is no cleaner way to do this ...\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "    norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "    bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "    embcat, emb]:\n",
    "    t.retain_grad()\n",
    "    \n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d276b27-73b1-4688-951d-06fdc144dba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Backprop through the whole thing manually, backpropagating through exactly all of the variables\n",
    "as they are defined in the forward pass above, one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9505f-7460-48b7-8cf6-a531916569d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad0fd759-092b-4ff9-82a3-b30639561473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "torch.Size([32])\n",
      "torch.Size([32, 27])\n",
      "torch.Size([32])\n",
      "tensor(3.3531, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "print(logprobs[range(n), Yb].shape)\n",
    "print(logprobs.shape)\n",
    "print(Yb.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "802e5b5e-0fd3-4e1a-b86d-fedfae7f033f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5593628-bf64-4da3-8b04-90d586a6812f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([-3.8325, -3.8673, -3.3982, -4.1356, -3.3071, -3.3339, -2.5516, -3.0462,\n",
      "        -3.2896, -3.3666, -3.4333, -3.2647, -2.8490, -3.0572, -4.2483, -3.7085,\n",
      "        -3.5419, -3.7807, -3.5311, -2.3494, -3.0832, -3.4361, -3.2682, -2.9962,\n",
      "        -3.4010, -3.7863, -3.6611], grad_fn=<SelectBackward0>)\n",
      "tensor(-3.3666, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "someIndex = 19\n",
    "print(Yb[someIndex].item())\n",
    "print(logprobs[someIndex])\n",
    "print(logprobs[someIndex, Yb[someIndex]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79d095-4ad6-4006-a90d-4b46398a5e01",
   "metadata": {},
   "source": [
    "dlogprobs will hold the derivative of the loss with respect to all the elements of logprobs. For this reason, it will also have the same shape as logprobs.\n",
    "\n",
    "Now how does logprobs influence the loss? Remember Yb is just an array of all the correct indices of the next character.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d846956-52ad-44b3-9a12-dbad3d6c893c",
   "metadata": {},
   "source": [
    "loss = -(a + b + c) / 3\n",
    "\n",
    "loss = -a/3 - b/3 - c/3\n",
    "\n",
    "So what is the derivative of the loss with respect to a?\n",
    "\n",
    "dloss/da = -1/3\n",
    "\n",
    "So the derivative is 1/n where n is the number of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe218cfb-a76a-42aa-bdfa-59f482e80021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf765af-c32d-4390-8b8f-c1657900c083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogprobs[range(n), Yb] = -1.0/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64fbd8cd-cfbe-4fc0-b599-21b6c4cad124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350f1dc2-3d59-4451-878e-21cf04e985d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs[someIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09c20150-0945-497d-958e-f8fbf82a7b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a344a4-e5e7-45d6-b6a9-96afd8315281",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### logprobs = probs.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f30da7-bc2e-42c8-861a-5dce39faadda",
   "metadata": {},
   "source": [
    "![](images/dxlogx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd72b4-259f-4c8a-b855-0a7f2894f9ba",
   "metadata": {},
   "source": [
    "In our example, x is probs, so the local derivate of probs.log() is simply (1.0 / probs).\n",
    "\n",
    "And because of the chain rule, we multiply that by dlogprobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76309828-0a1a-47f9-a1b2-7ec7a5dd3b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e67852-6ef1-4c35-8adb-15c1838aa383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634fef9-21d9-4fa5-8f03-d11dfcf8232d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### probs = counts * counts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "933d2df2-279a-49fb-8582-a8c6078a57fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "474a118b-145e-43fe-9407-76c959824568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = a * b, but with tensors:\n",
    "# a[3x3] * b[3x1] --->\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b3\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "# c[3x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cc98f46-7cd7-4275-8750-3e12a74a8a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9d1150c-f054-405a-b8a7-19b2f4f13d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e31fae5-439d-4bc2-ae3a-a9e941562e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts = (counts_sum_inv * dprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c32201-3046-4812-8118-7404289fc2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum_inv = counts_sum**-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb49f8-933c-4a1b-a5ce-a783cb5b04f3",
   "metadata": {},
   "source": [
    "![](images/ddx1_x.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a7dced4-4046-47a8-9e8a-b0b86596a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "989342ec-d642-4195-9039-88c3f5f5cd51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f2f1c-fb47-4974-9240-51caa7a89ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum = counts.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ee05909-e8b6-4b27-9bbc-5abfad5e365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add in the previous value we calculated for dcounts ... so use += \n",
    "dcounts += torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e8213d9-7ef1-4d1f-af5d-369850d3dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab2668-3a98-4490-97d2-832b90cd939d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts = norm_logits.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f3bae-039c-4dbc-92df-e9fe189ff15f",
   "metadata": {},
   "source": [
    "![](images/ddx_ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed793a-47bc-47b2-897a-808affc59dc6",
   "metadata": {},
   "source": [
    "The derivate of norm_logits.exp() is norm_logits.exp() which is already in counts, so let's just use counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e578f7e4-ed08-4e61-a3e5-2316add912c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnorm_logits = counts * dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be791f7b-2cb5-45c6-83a7-0f2d9f9c4221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37c448-9cd0-4efa-af85-2d21bc69974e",
   "metadata": {},
   "source": [
    "#### norm_logits = logits - logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a15e671-98f5-4d4d-8ba0-b248337d2085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapes are different ...\n",
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8293794a-149c-46af-85db-4c4f83a824b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c11 c12 c13 = a11 a12 a13 - b1\n",
    "# c21 c22 c23 = a21 a22 a23 - b2\n",
    "# c31 c32 c33 = a31 a32 a33 - b3\n",
    "\n",
    "# so e.g. c32 = a32 - b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5d0fc04-0de3-4972-88ef-c728b32ef037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogits = dnorm_logits.clone() # this is NOT our final derivative for dlogits!\n",
    "dlogit_maxes = (-dnorm_logits).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9f6b639-de88-4f71-876f-8c3ee4d3d9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828ba2-6f02-4c31-9d78-58f1572d9ac0",
   "metadata": {},
   "source": [
    "#### logit_maxes = logits.max(dim=1, keepdim=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "098cd840-f346-4696-810d-3b1621074016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice we use += because we need to add in the previous value\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1a52533-3bf3-4ec6-a0f3-219bf1c1bba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd2a576a620>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6371c5f6-c236-4845-b472-a39065e5acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logits',dlogits,logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe3b59-0d27-4668-b77f-7c5a220510fa",
   "metadata": {},
   "source": [
    "#### logits = h @ W2 + b2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5692b264-a720-4368-add3-4b7ca084da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits.shape => torch.Size([32, 27])\n",
      "h.shape =======> torch.Size([32, 64])\n",
      "W2.shape ======> torch.Size([64, 27])\n",
      "(h@W2).shape ==> torch.Size([32, 27])\n",
      "b2.shape ======> torch.Size([27])\n"
     ]
    }
   ],
   "source": [
    "print(f'dlogits.shape => {dlogits.shape}')\n",
    "print(f'h.shape =======> {h.shape}')\n",
    "print(f'W2.shape ======> {W2.shape}')\n",
    "print(f'(h@W2).shape ==> {(h@W2).shape}')\n",
    "print(f'b2.shape ======> {b2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75b269df-700d-4551-a583-cb8aaef250d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dh must have the same shape as h 32x64\n",
    "dh = dlogits @ W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6ec24bf-74f7-4c2b-a4d0-1f623702a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dW2 must have the same shape as W2 64x27\n",
    "dW2 = h.T @ dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a253d2f4-2bef-46cd-9b29-f4c073b5220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db2 must have the same shape as b2 27\n",
    "db2 = dlogits.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff5db4c5-0685-41b0-8196-5111f4db537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate True  | maxdiff 0.0\n",
      "W2              | exact: True  | approximate True  | maxdiff 0.0\n",
      "b2              | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('h',dh,h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dbcae-b5fe-449a-a32f-066582eeb57f",
   "metadata": {},
   "source": [
    "#### h = torch.tanh(hpreact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158ccc5-b2ab-48ec-be5f-3667c9e6b754",
   "metadata": {},
   "source": [
    "![](images/ddx_tanh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17412276-878c-4395-ab28-2cd9e503eebd",
   "metadata": {},
   "source": [
    "Notice the derivate of tanh(z) is 1 - a**2, where a is the output of tanh, not the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a959826c-dc2b-4820-901b-f044eee731a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, the chain rule ... so multiply by dh\n",
    "dhpreact = (1.0 - h**2) * dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dde0baf9-0685-43fc-946c-0b1b9e97f2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# I think this is not exact just due to some rounding differences ... \n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "\n",
    "# We get this result every time we restart the kernel and run all ...\n",
    "# hpreact         | exact: False | approximate True  | maxdiff 4.656612873077393e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b732dc5e-30dc-420f-9b00-4689764b0257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(dhpreact == hpreact.grad).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01f068c1-bf5e-45d7-8e5f-971f0fc08dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(dhpreact, hpreact.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8dc6a2c9-162d-4fd8-9ff8-77532d1c79c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.656612873077393e-10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dhpreact - hpreact.grad).abs().max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7341631b-c9a5-405e-a404-4b3e8c2a976b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-1.1642e-10,  0.0000e+00, -5.8208e-11,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-3.6380e-12,  0.0000e+00, -1.1642e-10,  ...,  0.0000e+00,\n",
       "         -2.9104e-11, -5.8208e-11],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -2.3283e-10,  ...,  0.0000e+00,\n",
       "          5.8208e-11,  1.1642e-10],\n",
       "        [ 7.2760e-12,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          2.9104e-11,  0.0000e+00]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dhpreact - hpreact.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dabfd-9094-4a2e-85bb-f938544879ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
