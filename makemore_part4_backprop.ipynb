{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7b64f-42fd-4a83-aefe-7d60678c3cf0",
   "metadata": {},
   "source": [
    "Tuesday, June 13, 2023\n",
    "\n",
    "This video shows how to manually implement back propogation in a multi layer perceptron.\n",
    "\n",
    "docker container start sad_nightingale\n",
    "\n",
    "[Building makemore Part 4: Becoming a Backprop Ninja](https://www.youtube.com/watch?v=q8SA3rM6ckI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25e9341-c435-4be5-ac56-0225357b4d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c49cadd-9445-4c55-bb23-a5aff6200d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7c8aeb-0294-4ee3-b983-4e161201afb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "lenOfWords = len(words)\n",
    "print(lenOfWords)\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c51f71-77c2-40e7-a827-632a5947e89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3cd2a0-d8e2-4f08-8e00-efd0249d7552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8b147f-c618-47c6-b510-6ee2074aaf00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "stoi[delimiter] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b8f870-e3d5-44cd-a6b9-3f04b75252c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "itos = { c:i for i, c in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7fcbb34-7767-4608-8ad7-b7fa04046c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f1fed5e-846d-4f9e-af94-8f3a3d5881b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + delimiter:\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a6c897-d864-47ff-bde1-16df400e23ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thgttg = 42\n",
    "manualSeed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aafd307-ad2e-430a-8ad6-c37fff7f3ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(thgttg)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e6995a-ecec-4801-8344-b61f36463ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626 28829\n"
     ]
    }
   ],
   "source": [
    "n1 = int(0.8 * lenOfWords)\n",
    "n2 = int(0.9 * lenOfWords)\n",
    "print(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3ba7b7-0f67-42b0-ae1c-377507dc1dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86a285df-b211-4b95-92eb-5cd2cb0f94a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ok boilerplate code is done, now we get to the action ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc684e22-ad13-4116-903e-5acebd5b65f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "all(input) -> Tensor\n",
       "\n",
       "Tests if all elements in :attr:`input` evaluate to `True`.\n",
       "\n",
       ".. note:: This function matches the behaviour of NumPy in returning\n",
       "          output of dtype `bool` for all supported dtypes except `uint8`.\n",
       "          For `uint8` the dtype of output is `uint8` itself.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(1, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[False, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a)\n",
       "    tensor(False, dtype=torch.bool)\n",
       "    >>> a = torch.arange(0, 3)\n",
       "    >>> a\n",
       "    tensor([0, 1, 2])\n",
       "    >>> torch.all(a)\n",
       "    tensor(False)\n",
       "\n",
       ".. function:: all(input, dim, keepdim=False, *, out=None) -> Tensor\n",
       "   :noindex:\n",
       "\n",
       "For each row of :attr:`input` in the given dimension :attr:`dim`,\n",
       "returns `True` if all elements in the row evaluate to `True` and `False` otherwise.\n",
       "\n",
       "If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
       "as :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
       "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
       "the output tensor having 1 fewer dimension than :attr:`input`.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    dim (int): the dimension to reduce.\n",
       "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(4, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[True, True],\n",
       "            [True, False],\n",
       "            [True, True],\n",
       "            [True, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=1)\n",
       "    tensor([ True, False,  True,  True], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=0)\n",
       "    tensor([ True, False], dtype=torch.bool)\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.all??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d7c7971-604e-4dd2-a68b-a9d33b4ba034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> bool\n",
       "\n",
       "This function checks if all :attr:`input` and :attr:`other` satisfy the condition:\n",
       "\n",
       ".. math::\n",
       "    \\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n",
       "\n",
       "elementwise, for all elements of :attr:`input` and :attr:`other`. The behaviour of this function is analogous to\n",
       "`numpy.allclose <https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html>`_\n",
       "\n",
       "Args:\n",
       "    input (Tensor): first tensor to compare\n",
       "    other (Tensor): second tensor to compare\n",
       "    atol (float, optional): absolute tolerance. Default: 1e-08\n",
       "    rtol (float, optional): relative tolerance. Default: 1e-05\n",
       "    equal_nan (bool, optional): if ``True``, then two ``NaN`` s will be considered equal. Default: ``False``\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\n",
       "    True\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\n",
       "    True\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.allclose??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "547d57bd-92a1-4d3c-9bf5-b2c7669c81cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function we weill use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate {str(app):5s} | maxdiff {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52b92be0-1a5d-4719-b326-15e1fa06413c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(manualSeed) # for reproducability\n",
    "\n",
    "# the embedding table for the characters ...\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/ ((n_embd * block_size) ** 0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of batch normalization\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# Note: I am initializing many of these parameters in non-standard ways\n",
    "# because sometimes initializing with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cd584d9-3904-4556-80fb-23f470f435d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a sorter variable, also for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86e31c48-7070-4f53-bf95-d76a0237d1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.sum??\n",
    "# Docstring:\n",
    "# sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
    "\n",
    "# See :func:`torch.sum`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee09c314-3285-496a-92a5-e8f5db1f84c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 2 + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc54fb01-8129-47a6-abba-7107f7ec0a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.max??\n",
    "# Docstring:\n",
    "# max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
    "\n",
    "# See :func:`torch.max`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3feb65-ab62-4aec-9500-4516a28deb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3513, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# Batch Normalization Layer\n",
    "bnmeani = 1/n * hprebn.sum(dim=0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(dim=0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-Linearity\n",
    "h = torch.tanh(hpreact)\n",
    "\n",
    "# Linear Layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(dim=1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(dim=1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 # if we use (1.0 / counts_sum) instead then we can't get backprop to be bit exact ... \n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "    \n",
    "# PyTorch retain_grad => Enables this Tensor to have their grad populated during backward(). \n",
    "# This is a no-op for leaf tensors\n",
    "\n",
    "# afaik there is no cleaner way to do this ...\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "    norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "    bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "    embcat, emb]:\n",
    "    t.retain_grad()\n",
    "    \n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d276b27-73b1-4688-951d-06fdc144dba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Backprop through the whole thing manually, backpropagating through exactly all of the variables\n",
    "as they are defined in the forward pass above, one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9505f-7460-48b7-8cf6-a531916569d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad0fd759-092b-4ff9-82a3-b30639561473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "torch.Size([32])\n",
      "torch.Size([32, 27])\n",
      "torch.Size([32])\n",
      "tensor(3.3513, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "print(logprobs[range(n), Yb].shape)\n",
    "print(logprobs.shape)\n",
    "print(Yb.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "802e5b5e-0fd3-4e1a-b86d-fedfae7f033f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5593628-bf64-4da3-8b04-90d586a6812f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([-3.7835, -3.8599, -3.3530, -4.0229, -3.4052, -3.2706, -2.6978, -2.9681,\n",
      "        -3.4067, -3.4181, -3.5741, -3.1179, -2.7734, -2.8910, -4.4534, -3.7855,\n",
      "        -3.5936, -3.9189, -3.5440, -2.3793, -3.0322, -3.3747, -3.0861, -3.0590,\n",
      "        -3.4481, -3.7783, -3.7195], grad_fn=<SelectBackward0>)\n",
      "tensor(-3.4181, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "someIndex = 19\n",
    "print(Yb[someIndex].item())\n",
    "print(logprobs[someIndex])\n",
    "print(logprobs[someIndex, Yb[someIndex]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79d095-4ad6-4006-a90d-4b46398a5e01",
   "metadata": {},
   "source": [
    "dlogprobs will hold the derivative of the loss with respect to all the elements of logprobs. For this reason, it will also have the same shape as logprobs.\n",
    "\n",
    "Now how does logprobs influence the loss? Remember Yb is just an array of all the correct indices of the next character.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d846956-52ad-44b3-9a12-dbad3d6c893c",
   "metadata": {},
   "source": [
    "loss = -(a + b + c) / 3\n",
    "\n",
    "loss = -a/3 - b/3 - c/3\n",
    "\n",
    "So what is the derivative of the loss with respect to a?\n",
    "\n",
    "dloss/da = -1/3\n",
    "\n",
    "So the derivative is 1/n where n is the number of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe218cfb-a76a-42aa-bdfa-59f482e80021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddf765af-c32d-4390-8b8f-c1657900c083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogprobs[range(n), Yb] = -1.0/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64fbd8cd-cfbe-4fc0-b599-21b6c4cad124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "350f1dc2-3d59-4451-878e-21cf04e985d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs[someIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09c20150-0945-497d-958e-f8fbf82a7b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a344a4-e5e7-45d6-b6a9-96afd8315281",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### logprobs = probs.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f30da7-bc2e-42c8-861a-5dce39faadda",
   "metadata": {},
   "source": [
    "![](images/dxlogx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd72b4-259f-4c8a-b855-0a7f2894f9ba",
   "metadata": {},
   "source": [
    "In our example, x is probs, so the local derivate of probs.log() is simply (1.0 / probs).\n",
    "\n",
    "And because of the chain rule, we multiply that by dlogprobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76309828-0a1a-47f9-a1b2-7ec7a5dd3b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e67852-6ef1-4c35-8adb-15c1838aa383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634fef9-21d9-4fa5-8f03-d11dfcf8232d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### probs = counts * counts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "933d2df2-279a-49fb-8582-a8c6078a57fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "474a118b-145e-43fe-9407-76c959824568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = a * b, but with tensors:\n",
    "# a[3x3] * b[3x1] --->\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b3\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "# c[3x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cc98f46-7cd7-4275-8750-3e12a74a8a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9d1150c-f054-405a-b8a7-19b2f4f13d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e31fae5-439d-4bc2-ae3a-a9e941562e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts = (counts_sum_inv * dprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c32201-3046-4812-8118-7404289fc2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum_inv = counts_sum**-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb49f8-933c-4a1b-a5ce-a783cb5b04f3",
   "metadata": {},
   "source": [
    "![](images/ddx1_x.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a7dced4-4046-47a8-9e8a-b0b86596a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "989342ec-d642-4195-9039-88c3f5f5cd51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f2f1c-fb47-4974-9240-51caa7a89ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum = counts.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ee05909-e8b6-4b27-9bbc-5abfad5e365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add in the previous value we calculated for dcounts ... so use += \n",
    "dcounts += torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e8213d9-7ef1-4d1f-af5d-369850d3dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab2668-3a98-4490-97d2-832b90cd939d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts = norm_logits.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f3bae-039c-4dbc-92df-e9fe189ff15f",
   "metadata": {},
   "source": [
    "![](images/ddx_ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed793a-47bc-47b2-897a-808affc59dc6",
   "metadata": {},
   "source": [
    "The derivate of norm_logits.exp() is norm_logits.exp() which is already in counts, so let's just use counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e578f7e4-ed08-4e61-a3e5-2316add912c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnorm_logits = counts * dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be791f7b-2cb5-45c6-83a7-0f2d9f9c4221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37c448-9cd0-4efa-af85-2d21bc69974e",
   "metadata": {},
   "source": [
    "#### norm_logits = logits - logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a15e671-98f5-4d4d-8ba0-b248337d2085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapes are different ...\n",
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8293794a-149c-46af-85db-4c4f83a824b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c11 c12 c13 = a11 a12 a13 - b1\n",
    "# c21 c22 c23 = a21 a22 a23 - b2\n",
    "# c31 c32 c33 = a31 a32 a33 - b3\n",
    "\n",
    "# so e.g. c32 = a32 - b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5d0fc04-0de3-4972-88ef-c728b32ef037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogits = dnorm_logits.clone() # this is NOT our final derivative for dlogits!\n",
    "dlogit_maxes = (-dnorm_logits).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9f6b639-de88-4f71-876f-8c3ee4d3d9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828ba2-6f02-4c31-9d78-58f1572d9ac0",
   "metadata": {},
   "source": [
    "#### logit_maxes = logits.max(dim=1, keepdim=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "098cd840-f346-4696-810d-3b1621074016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice we use += because we need to add in the previous value\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1a52533-3bf3-4ec6-a0f3-219bf1c1bba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd82827d660>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6371c5f6-c236-4845-b472-a39065e5acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logits',dlogits,logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe3b59-0d27-4668-b77f-7c5a220510fa",
   "metadata": {},
   "source": [
    "#### logits = h @ W2 + b2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5692b264-a720-4368-add3-4b7ca084da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits.shape => torch.Size([32, 27])\n",
      "h.shape =======> torch.Size([32, 64])\n",
      "W2.shape ======> torch.Size([64, 27])\n",
      "(h@W2).shape ==> torch.Size([32, 27])\n",
      "b2.shape ======> torch.Size([27])\n"
     ]
    }
   ],
   "source": [
    "print(f'dlogits.shape => {dlogits.shape}')\n",
    "print(f'h.shape =======> {h.shape}')\n",
    "print(f'W2.shape ======> {W2.shape}')\n",
    "print(f'(h@W2).shape ==> {(h@W2).shape}')\n",
    "print(f'b2.shape ======> {b2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75b269df-700d-4551-a583-cb8aaef250d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dh must have the same shape as h 32x64\n",
    "dh = dlogits @ W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6ec24bf-74f7-4c2b-a4d0-1f623702a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dW2 must have the same shape as W2 64x27\n",
    "dW2 = h.T @ dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a253d2f4-2bef-46cd-9b29-f4c073b5220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db2 must have the same shape as b2 27\n",
    "db2 = dlogits.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff5db4c5-0685-41b0-8196-5111f4db537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate True  | maxdiff 0.0\n",
      "W2              | exact: True  | approximate True  | maxdiff 0.0\n",
      "b2              | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('h',dh,h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dbcae-b5fe-449a-a32f-066582eeb57f",
   "metadata": {},
   "source": [
    "#### h = torch.tanh(hpreact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158ccc5-b2ab-48ec-be5f-3667c9e6b754",
   "metadata": {},
   "source": [
    "![](images/ddx_tanh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17412276-878c-4395-ab28-2cd9e503eebd",
   "metadata": {},
   "source": [
    "Notice the derivate of tanh(z) is 1 - a**2, where a is the output of tanh, not the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a959826c-dc2b-4820-901b-f044eee731a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, the chain rule ... so multiply by dh\n",
    "dhpreact = (1.0 - h**2) * dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dde0baf9-0685-43fc-946c-0b1b9e97f2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# I think this is not exact just due to some rounding differences ... \n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "\n",
    "# We get this result ALMOST every time we restart the kernel and run all ...\n",
    "# hpreact         | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n",
    "\n",
    "# hmm other times we can get this ..\n",
    "# hpreact         | exact: False | approximate True  | maxdiff 9.313225746154785e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b732dc5e-30dc-420f-9b00-4689764b0257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(dhpreact == hpreact.grad).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01f068c1-bf5e-45d7-8e5f-971f0fc08dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(dhpreact, hpreact.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8dc6a2c9-162d-4fd8-9ff8-77532d1c79c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.313225746154785e-10"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dhpreact - hpreact.grad).abs().max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7341631b-c9a5-405e-a404-4b3e8c2a976b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.3656e-11,\n",
       "          0.0000e+00, -1.1642e-10],\n",
       "        [ 0.0000e+00,  0.0000e+00, -5.8208e-11,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  5.8208e-11,  ...,  0.0000e+00,\n",
       "         -2.9104e-11,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 2.3283e-10,  2.9104e-11,  0.0000e+00,  ...,  0.0000e+00,\n",
       "         -1.1642e-10, -5.8208e-11],\n",
       "        [ 7.2760e-12,  0.0000e+00,  0.0000e+00,  ..., -1.1642e-10,\n",
       "         -8.7311e-11,  0.0000e+00]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dhpreact - hpreact.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a6dabfd-9094-4a2e-85bb-f938544879ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "not_equal = torch.not_equal(dhpreact, hpreact.grad)\n",
    "plt.imshow(not_equal, cmap='binary')\n",
    "plt.show()\n",
    "# white cells are equal ... why do we not see all white cells?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d881fa-c70a-4f8b-b828-df68ca6fe5a6",
   "metadata": {},
   "source": [
    "We now begin back propogation through the batch normalization layer. This is discussed in the paper \n",
    "\n",
    "[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b095f2e3-c9cf-4f3a-8744-0ddb0ed74eae",
   "metadata": {},
   "source": [
    "![](images/BatchNormalizationLayer.png)\n",
    "![](images/BatchNormalizingTransform.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af860b77-2731-468a-87e7-1379adbc6f17",
   "metadata": {},
   "source": [
    "#### hpreact = bngain * bnraw + bnbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0f5bf31-d55c-4b30-8635-0d1fbe6a964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact.shape => torch.Size([32, 64])\n",
      "bngain.shape => torch.Size([1, 64])\n",
      "bnraw.shape => torch.Size([32, 64])\n",
      "(bngain * bnraw).shape => torch.Size([32, 64])\n",
      "bnbias.shape => torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'hpreact.shape => {hpreact.shape}')\n",
    "print(f'bngain.shape => {bngain.shape}')\n",
    "print(f'bnraw.shape => {bnraw.shape}')\n",
    "print(f'(bngain * bnraw).shape => {(bngain*bnraw).shape}')\n",
    "print(f'bnbias.shape => {bnbias.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e1bf8a7-2fca-46cb-ad1d-55f7f80c6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbngain = (bnraw * dhpreact).sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85d51d28-9050-421f-a85f-5680b310acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnraw = (bngain * dhpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de9b2c7b-64e2-4a79-9b61-9c88ede166f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnbias = dhpreact.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c344b27a-9bfb-4d60-ab9b-8c9f5f04406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngain          | exact: False | approximate True  | maxdiff 2.3283064365386963e-09\n",
      "bnraw           | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n",
      "bnbias          | exact: False | approximate True  | maxdiff 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba434b1-d388-4ca6-8f75-6f797cb0f702",
   "metadata": {},
   "source": [
    "#### bnraw = bndiff * bnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c34af17a-9e37-4776-80c3-73ec432ffa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff.shape => torch.Size([32, 64])\n",
      "bnvar_inv.shape => torch.Size([1, 64])\n",
      "(bndiff * bnvar_inv).shape => torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'bndiff.shape => {bndiff.shape}')\n",
    "print(f'bnvar_inv.shape => {bnvar_inv.shape}')\n",
    "print(f'(bndiff * bnvar_inv).shape => {((bndiff * bnvar_inv).shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81bb23cc-971f-4342-8ab4-216d624f8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff = bnvar_inv * dbnraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7f1ead6-d760-448d-bf95-173b3cc0ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: False | approximate False | maxdiff 0.0011086449958384037\n"
     ]
    }
   ],
   "source": [
    "cmp('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c62f58a1-e214-495f-98e1-cc0126aa552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar_inv = (bndiff * dbnraw).sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8730782d-7dec-43cd-9f61-a96ee94cbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar_inv       | exact: False | approximate True  | maxdiff 4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71079ecb-2625-42ac-ba6a-8745c42ad428",
   "metadata": {},
   "source": [
    "#### bnvar_inv = (bnvar + 1e-5)**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0dc6e5be-3ef1-47ec-964b-b7ef04f0f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4dedefe6-0c64-4f30-95ef-9d427dfd36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: False | approximate True  | maxdiff 7.566995918750763e-10\n"
     ]
    }
   ],
   "source": [
    "cmp('bnvar', dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de820967-5295-4a70-b159-87902edbe97a",
   "metadata": {},
   "source": [
    "#### bnvar = 1/(n-1) * (bndiff2).sum(dim=0, keepdim=True)\n",
    "\n",
    "[Bessel's Correction](https://mathcenter.oxford.emory.edu/site/math117/besselCorrection/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1a9b3bb-6893-4335-9c04-01b1b2364cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar.shape ===> torch.Size([1, 64])\n",
      "bndiff2.shape => torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'bnvar.shape ===> {bnvar.shape}')\n",
    "print(f'bndiff2.shape => {bndiff2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "40096ebb-9eae-47d9-896c-8daf41cc06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a11 a12\n",
    "# a21 a22\n",
    "# ----->\n",
    "# b1, b2, where:\n",
    "# b1 = 1/(n-1)*(a11 + a21)\n",
    "# b2 = 1/(n-1)*(a12 + a22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c3fccb6-df0e-478b-80db-5f6370a0c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16d6bc7a-f9a9-4ebc-a2e3-0bfd8c7eb2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff2         | exact: False | approximate True  | maxdiff 2.3646862246096134e-11\n"
     ]
    }
   ],
   "source": [
    "cmp('bndiff2',dbndiff2, bndiff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69729b-d049-4c70-815e-48b8d127af28",
   "metadata": {},
   "source": [
    "#### bndiff2 = bndiff**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "846c1a4c-ba18-4d38-9e4b-ef9015e72647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7362b02b-e3b7-445d-9e5a-c556d1445dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we have to add in the previous calculation of bndiff with +=\n",
    "dbndiff += (2*bndiff) * dbndiff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cc4642fc-a3fd-4a8e-9042-3354f39c5457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "cmp('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0847ca9-867b-4b41-a8d7-16517ad82d88",
   "metadata": {},
   "source": [
    "#### bndiff = hprebn - bnmeani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef2f52bb-4f95-4d1a-a596-6129e42b0648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16319e4e-d0c7-4a3a-93a1-4bd71491a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn = dbndiff.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62509864-ae5b-41a0-a654-0c0c32eba47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate False | maxdiff 0.001013938570395112\n"
     ]
    }
   ],
   "source": [
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f2b13f5-347d-4bf5-a4b3-0180c302f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnmeani = (-torch.ones_like(bndiff) * dbndiff).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49c60118-207d-4357-a396-dc5769154f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can actually just replace the above line with this ..\n",
    "# because ..\n",
    "# torch.ones_like(bndiff)\n",
    "# is just multiplying by 1 ... \n",
    "dbnmeani = (-dbndiff).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d8827de-058b-48a8-946b-06338bb389ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnmeani         | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('bnmeani', dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aae202-5c22-4f21-9de1-b40f51577558",
   "metadata": {},
   "source": [
    "#### bnmeani = 1/n * hprebn.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a4872e9-10d1-40ea-99fd-d8741d8067d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, we += this from the previous value ... \n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd5576b0-2abf-4106-b3ee-8776d68de7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08cbf0-1e70-4fbc-a586-6295a5b4c20e",
   "metadata": {},
   "source": [
    "So now we have finished back propagating through the batch normalization layer. We can now back propagate linear layer 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27653e-0330-4c72-87a8-c2772320093c",
   "metadata": {},
   "source": [
    "#### hprebn = embcat @ W1 + b1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92a9192d-a3d4-4f6c-8bd5-afde77201956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, embcat.shape, W1.shape, b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aca127eb-06fb-4c9a-a45b-7835687d2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40e7c413-b588-49a9-863e-85c5d6c8b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embcat          | exact: False | approximate True  | maxdiff 1.3969838619232178e-09\n",
      "W1              | exact: False | approximate True  | maxdiff 3.725290298461914e-09\n",
      "b1              | exact: False | approximate True  | maxdiff 2.7939677238464355e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f43952-48ed-472c-8940-2f0f17b7a4a2",
   "metadata": {},
   "source": [
    "#### embcat = emb.view(emb.shape[0], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8942525-4b8e-410e-b589-7b90aca2386a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 3, 10]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embcat.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38f661b2-ad33-40f5-92b6-b728e4c67b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demb = dembcat.view(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17eed703-cb1d-488b-8c56-ef8928915fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: False | approximate True  | maxdiff 1.3969838619232178e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('emb', demb, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d25ff7-595e-4a09-af89-8d675082ae2a",
   "metadata": {},
   "source": [
    "#### emb = C[Xb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f56c9e2b-eb42-43ba-b435-494b7eae6841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10]) torch.Size([27, 10]) torch.Size([32, 3])\n",
      "tensor([[ 1,  1,  4],\n",
      "        [18, 14,  1],\n",
      "        [11,  5,  9],\n",
      "        [ 0,  0,  1],\n",
      "        [12, 15, 14]])\n"
     ]
    }
   ],
   "source": [
    "# forward pass: emb = C[Xb]\n",
    "print(emb.shape, C.shape, Xb.shape)\n",
    "print(Xb[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6db98868-2b54-4ecb-921d-72e8ae6ecedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = torch.zeros_like(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6eb5a21e-e5a1-451a-8972-e07a2d94946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "919df79b-7767-4943-89c0-a758aa3b0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: False | approximate True  | maxdiff 4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8faa4a-90e6-4443-b381-75518ee0fb12",
   "metadata": {},
   "source": [
    "Run all the comparison statements together to get the overview of how we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1fe641d-6202-427f-ae5d-7793ff7e61bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate True  | maxdiff 0.0\n",
      "probs           | exact: True  | approximate True  | maxdiff 0.0\n",
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff 0.0\n",
      "counts_sum      | exact: True  | approximate True  | maxdiff 0.0\n",
      "counts          | exact: True  | approximate True  | maxdiff 0.0\n",
      "norm_logits     | exact: True  | approximate True  | maxdiff 0.0\n",
      "logit_maxes     | exact: True  | approximate True  | maxdiff 0.0\n",
      "logits          | exact: True  | approximate True  | maxdiff 0.0\n",
      "h               | exact: True  | approximate True  | maxdiff 0.0\n",
      "W2              | exact: True  | approximate True  | maxdiff 0.0\n",
      "b2              | exact: True  | approximate True  | maxdiff 0.0\n",
      "hpreact         | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n",
      "bngain          | exact: False | approximate True  | maxdiff 2.3283064365386963e-09\n",
      "bnbias          | exact: False | approximate True  | maxdiff 3.725290298461914e-09\n",
      "bnraw           | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n",
      "bnvar_inv       | exact: False | approximate True  | maxdiff 4.6566128730773926e-09\n",
      "bnvar           | exact: False | approximate True  | maxdiff 7.566995918750763e-10\n",
      "bndiff2         | exact: False | approximate True  | maxdiff 2.3646862246096134e-11\n",
      "bndiff          | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n",
      "bnmeani         | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n",
      "hprebn          | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n",
      "embcat          | exact: False | approximate True  | maxdiff 1.3969838619232178e-09\n",
      "W1              | exact: False | approximate True  | maxdiff 3.725290298461914e-09\n",
      "b1              | exact: False | approximate True  | maxdiff 2.7939677238464355e-09\n",
      "emb             | exact: False | approximate True  | maxdiff 1.3969838619232178e-09\n",
      "C               | exact: False | approximate True  | maxdiff 4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5ce5941-d128-471c-bbdb-2481d325af77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.351276159286499 diff: 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c974dfc5-975e-40c5-88b5-d204d78eb9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate True  | maxdiff 7.2177499532699585e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f78d9be2-c7d6-4a35-b1a8-f99defc978ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "16e9ab07-0826-47cb-a088-acb0106af4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0641, 0.0855, 0.0202, 0.0512, 0.0192, 0.0922, 0.0254, 0.0364, 0.0173,\n",
       "        0.0325, 0.0333, 0.0346, 0.0394, 0.0291, 0.0305, 0.0132, 0.0092, 0.0195,\n",
       "        0.0155, 0.0580, 0.0481, 0.0214, 0.0264, 0.0670, 0.0610, 0.0273, 0.0226],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d333e3c4-dc6a-440b-9a48-352924f2e34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0641,  0.0855,  0.0202,  0.0512,  0.0192,  0.0922,  0.0254,  0.0364,\n",
       "        -0.9827,  0.0325,  0.0333,  0.0346,  0.0394,  0.0291,  0.0305,  0.0132,\n",
       "         0.0092,  0.0195,  0.0155,  0.0580,  0.0481,  0.0214,  0.0264,  0.0670,\n",
       "         0.0610,  0.0273,  0.0226], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8852e9ef-22b2-4a69-affe-9867b1f4879d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3283e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "087eb1f9-7064-4835-b62f-3a0702793ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd828048ac0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "26cf8e7d-740a-45bc-b538-c70adfd58f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1fd68be6-6855-4784-8829-67927b438f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate True  | maxdiff 6.984919309616089e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c6528a6e-2481-406d-819d-05e5156ad853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "055e1576-2d20-415b-acc1-6feec586b992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95d4b9df-0b0d-4508-bde9-322d1d1da0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.8500\n",
      "  10000/ 200000: 2.2031\n",
      "  20000/ 200000: 2.3493\n",
      "  30000/ 200000: 2.4731\n",
      "  40000/ 200000: 2.0106\n",
      "  50000/ 200000: 2.3401\n",
      "  60000/ 200000: 2.3747\n",
      "  70000/ 200000: 2.0174\n",
      "  80000/ 200000: 2.3383\n",
      "  90000/ 200000: 2.1910\n",
      " 100000/ 200000: 2.0133\n",
      " 110000/ 200000: 2.3770\n",
      " 120000/ 200000: 2.0207\n",
      " 130000/ 200000: 2.5074\n",
      " 140000/ 200000: 2.2609\n",
      " 150000/ 200000: 2.1258\n",
      " 160000/ 200000: 1.9279\n",
      " 170000/ 200000: 1.8082\n",
      " 180000/ 200000: 1.9865\n",
      " 190000/ 200000: 1.8651\n",
      "CPU times: user 42min 52s, sys: 2.86 s, total: 42min 54s\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break\n",
    "\n",
    "# CPU times: user 41min 7s, sys: 2.9 s, total: 41min 10s\n",
    "# Wall time: 5min 23s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd4b91-3cd4-4522-b9a2-b42584d2142b",
   "metadata": {},
   "source": [
    "### Finally, Let's run everything on the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d7a9efe-488e-4045-95ea-0b692f092793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU if GPU is not available\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c003e232-7684-4bb5-aaf8-8cab133781c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to force device for the remaining code, do it here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf5a3-b5af-4cd6-88e8-8915324344d3",
   "metadata": {},
   "source": [
    "Is there some way to get the above code running on the GPU WITHOUT adding in all of the .to(device) code to every line we create a new tensor??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43999613-faa5-4470-8111-f72af3776d4d",
   "metadata": {},
   "source": [
    "#### We first of all need to load the dataset to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c38216ae-1586-43f1-a9bd-f061ec0afdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrGPU = Xtr.to(device)\n",
    "YtrGPU = Ytr.to(device)\n",
    "\n",
    "XdevGPU = Xdev.to(device)\n",
    "YdevGPU = Ydev.to(device)\n",
    "\n",
    "XteGPU = Xte.to(device)\n",
    "YteGPU = Yte.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec9998-6b24-4f67-a85b-82386b2fa428",
   "metadata": {},
   "source": [
    "#### Then tweak the code to use the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3aee816c-4fec-446f-b817-5653daacd5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g).to(device)\n",
    "# Layer 1\n",
    "W1 = (torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)).to(device)\n",
    "b1 = (torch.randn(n_hidden,                        generator=g) * 0.1).to(device)\n",
    "# Layer 2\n",
    "W2 = (torch.randn((n_hidden, vocab_size),          generator=g) * 0.1).to(device)\n",
    "b2 = (torch.randn(vocab_size,                      generator=g) * 0.1).to(device)\n",
    "# BatchNorm parameters\n",
    "bngain = (torch.randn((1, n_hidden))*0.1 + 1.0).to(device)\n",
    "bnbias = (torch.randn((1, n_hidden))*0.1).to(device)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b273e63-992e-441f-aacf-99a4c79f2478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.7795\n",
      "  10000/ 200000: 2.1717\n",
      "  20000/ 200000: 2.4130\n",
      "  30000/ 200000: 2.4210\n",
      "  40000/ 200000: 2.0331\n",
      "  50000/ 200000: 2.2745\n",
      "  60000/ 200000: 2.4246\n",
      "  70000/ 200000: 2.0621\n",
      "  80000/ 200000: 2.4008\n",
      "  90000/ 200000: 2.1472\n",
      " 100000/ 200000: 1.9258\n",
      " 110000/ 200000: 2.2893\n",
      " 120000/ 200000: 2.0140\n",
      " 130000/ 200000: 2.4013\n",
      " 140000/ 200000: 2.3603\n",
      " 150000/ 200000: 2.1417\n",
      " 160000/ 200000: 1.9309\n",
      " 170000/ 200000: 1.8732\n",
      " 180000/ 200000: 2.0348\n",
      " 190000/ 200000: 1.9127\n",
      "CPU times: user 11min 9s, sys: 279 ms, total: 11min 9s\n",
      "Wall time: 11min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, XtrGPU.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = XtrGPU[ix], YtrGPU[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66ceeba-ca98-477b-bffb-0145df086da9",
   "metadata": {},
   "source": [
    "Ok, that is ridiculous! Why is the above code running soo much slower than the CPU code? It is literally half the speed!! I am doubting it is even running on the GPU! \n",
    "\n",
    "Gonna redo the code a little differently ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "773d0b2d-41c0-444d-8abe-e3f3a1dfaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doubt this really is even needed, but gonna run it anyways ...\n",
    "g = None\n",
    "C = None\n",
    "W1 = None\n",
    "b1 = None\n",
    "W2 = None\n",
    "b2 = None\n",
    "bngain = None\n",
    "bnbias = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef9cc26a-5366-4b0c-9dc0-81d12bb2617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator(device=device).manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g, device=device)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g, device=device) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g, device=device) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g, device=device) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g, device=device) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden), device=device)*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden), device=device)*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5bb6e797-0cc2-4276-9d2c-d032e773a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.6193\n",
      "  10000/ 200000: 2.5983\n",
      "  20000/ 200000: 1.9748\n",
      "  30000/ 200000: 2.4369\n",
      "  40000/ 200000: 2.0644\n",
      "  50000/ 200000: 2.6719\n",
      "  60000/ 200000: 2.2973\n",
      "  70000/ 200000: 2.2144\n",
      "  80000/ 200000: 2.1684\n",
      "  90000/ 200000: 2.0491\n",
      " 100000/ 200000: 2.3221\n",
      " 110000/ 200000: 1.6753\n",
      " 120000/ 200000: 2.1570\n",
      " 130000/ 200000: 2.1407\n",
      " 140000/ 200000: 2.0796\n",
      " 150000/ 200000: 2.1221\n",
      " 160000/ 200000: 1.7140\n",
      " 170000/ 200000: 2.3287\n",
      " 180000/ 200000: 2.0945\n",
      " 190000/ 200000: 2.2459\n",
      "CPU times: user 11min 10s, sys: 182 ms, total: 11min 10s\n",
      "Wall time: 11min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, XtrGPU.shape[0], (batch_size,), generator=g, device=device)\n",
    "    Xb, Yb = XtrGPU[ix], YtrGPU[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af89166-4724-4296-9562-b997d5270919",
   "metadata": {},
   "source": [
    "I noticed as the above code ran, that there was 100% CPU utilization on 1 core ... why??\n",
    "\n",
    "Sigh. No difference in performance! Keep digging ... !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d4191-c6b4-42cf-ba72-189e8e84cbec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
