{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7b64f-42fd-4a83-aefe-7d60678c3cf0",
   "metadata": {},
   "source": [
    "Tuesday, June 13, 2023\n",
    "\n",
    "This video shows how to manually implement back propogation in a multi layer perceptron.\n",
    "\n",
    "docker container start sad_nightingale\n",
    "\n",
    "[Building makemore Part 4: Becoming a Backprop Ninja](https://www.youtube.com/watch?v=q8SA3rM6ckI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25e9341-c435-4be5-ac56-0225357b4d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c49cadd-9445-4c55-bb23-a5aff6200d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7c8aeb-0294-4ee3-b983-4e161201afb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "lenOfWords = len(words)\n",
    "print(lenOfWords)\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c51f71-77c2-40e7-a827-632a5947e89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3cd2a0-d8e2-4f08-8e00-efd0249d7552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8b147f-c618-47c6-b510-6ee2074aaf00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "stoi[delimiter] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b8f870-e3d5-44cd-a6b9-3f04b75252c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "itos = { c:i for i, c in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7fcbb34-7767-4608-8ad7-b7fa04046c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f1fed5e-846d-4f9e-af94-8f3a3d5881b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + delimiter:\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a6c897-d864-47ff-bde1-16df400e23ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thgttg = 42\n",
    "manualSeed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aafd307-ad2e-430a-8ad6-c37fff7f3ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(thgttg)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e6995a-ecec-4801-8344-b61f36463ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626 28829\n"
     ]
    }
   ],
   "source": [
    "n1 = int(0.8 * lenOfWords)\n",
    "n2 = int(0.9 * lenOfWords)\n",
    "print(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3ba7b7-0f67-42b0-ae1c-377507dc1dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Ytd = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86a285df-b211-4b95-92eb-5cd2cb0f94a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ok boilerplate code is done, now we get to the action ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc684e22-ad13-4116-903e-5acebd5b65f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "all(input) -> Tensor\n",
       "\n",
       "Tests if all elements in :attr:`input` evaluate to `True`.\n",
       "\n",
       ".. note:: This function matches the behaviour of NumPy in returning\n",
       "          output of dtype `bool` for all supported dtypes except `uint8`.\n",
       "          For `uint8` the dtype of output is `uint8` itself.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(1, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[False, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a)\n",
       "    tensor(False, dtype=torch.bool)\n",
       "    >>> a = torch.arange(0, 3)\n",
       "    >>> a\n",
       "    tensor([0, 1, 2])\n",
       "    >>> torch.all(a)\n",
       "    tensor(False)\n",
       "\n",
       ".. function:: all(input, dim, keepdim=False, *, out=None) -> Tensor\n",
       "   :noindex:\n",
       "\n",
       "For each row of :attr:`input` in the given dimension :attr:`dim`,\n",
       "returns `True` if all elements in the row evaluate to `True` and `False` otherwise.\n",
       "\n",
       "If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
       "as :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
       "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
       "the output tensor having 1 fewer dimension than :attr:`input`.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    dim (int): the dimension to reduce.\n",
       "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(4, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[True, True],\n",
       "            [True, False],\n",
       "            [True, True],\n",
       "            [True, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=1)\n",
       "    tensor([ True, False,  True,  True], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=0)\n",
       "    tensor([ True, False], dtype=torch.bool)\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.all??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d7c7971-604e-4dd2-a68b-a9d33b4ba034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> bool\n",
       "\n",
       "This function checks if all :attr:`input` and :attr:`other` satisfy the condition:\n",
       "\n",
       ".. math::\n",
       "    \\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n",
       "\n",
       "elementwise, for all elements of :attr:`input` and :attr:`other`. The behaviour of this function is analogous to\n",
       "`numpy.allclose <https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html>`_\n",
       "\n",
       "Args:\n",
       "    input (Tensor): first tensor to compare\n",
       "    other (Tensor): second tensor to compare\n",
       "    atol (float, optional): absolute tolerance. Default: 1e-08\n",
       "    rtol (float, optional): relative tolerance. Default: 1e-05\n",
       "    equal_nan (bool, optional): if ``True``, then two ``NaN`` s will be considered equal. Default: ``False``\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\n",
       "    True\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\n",
       "    True\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.allclose??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "547d57bd-92a1-4d3c-9bf5-b2c7669c81cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function we weill use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate {str(app):5s} | maxdiff {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52b92be0-1a5d-4719-b326-15e1fa06413c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(manualSeed) # for reproducability\n",
    "\n",
    "# the embedding table for the characters ...\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/ ((n_embd * block_size) ** 0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of batch normalization\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# Note: I am initializing many of these parameters in non-standard ways\n",
    "# because sometimes initializing with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cd584d9-3904-4556-80fb-23f470f435d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a sorter variable, also for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86e31c48-7070-4f53-bf95-d76a0237d1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.sum??\n",
    "# Docstring:\n",
    "# sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
    "\n",
    "# See :func:`torch.sum`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee09c314-3285-496a-92a5-e8f5db1f84c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 2 + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc54fb01-8129-47a6-abba-7107f7ec0a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.max??\n",
    "# Docstring:\n",
    "# max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
    "\n",
    "# See :func:`torch.max`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3feb65-ab62-4aec-9500-4516a28deb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3205, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# Batch Normalization Layer\n",
    "bnmeani = 1/n * hprebn.sum(dim=0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(dim=0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-Linearity\n",
    "h = torch.tanh(hpreact)\n",
    "\n",
    "# Linear Layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(dim=1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(dim=1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 # if we use (1.0 / counts_sum) instead then we can't get backprop to be bit exact ... \n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "    \n",
    "# PyTorch retain_grad => Enables this Tensor to have their grad populated during backward(). \n",
    "# This is a no-op for leaf tensors\n",
    "\n",
    "# afaik there is no cleaner way to do this ...\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "    norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "    bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "    embcat, emb]:\n",
    "    t.retain_grad()\n",
    "    \n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d276b27-73b1-4688-951d-06fdc144dba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Backprop through the whole thing manually, backpropagating through exactly all of the variables\n",
    "as they are defined in the forward pass above, one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9505f-7460-48b7-8cf6-a531916569d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad0fd759-092b-4ff9-82a3-b30639561473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "torch.Size([32])\n",
      "torch.Size([32, 27])\n",
      "torch.Size([32])\n",
      "tensor(3.3205, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "print(logprobs[range(n), Yb].shape)\n",
    "print(logprobs.shape)\n",
    "print(Yb.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "802e5b5e-0fd3-4e1a-b86d-fedfae7f033f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5593628-bf64-4da3-8b04-90d586a6812f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([-3.7271, -3.8575, -3.3370, -4.0878, -3.3874, -3.3987, -2.6237, -3.0210,\n",
      "        -3.3242, -3.2927, -3.5219, -3.1323, -2.8639, -2.9307, -4.2125, -3.7273,\n",
      "        -3.5671, -3.8301, -3.5310, -2.4596, -3.0061, -3.3564, -3.1455, -3.1611,\n",
      "        -3.4145, -3.6997, -3.6370], grad_fn=<SelectBackward0>)\n",
      "tensor(-3.2927, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "someIndex = 19\n",
    "print(Yb[someIndex].item())\n",
    "print(logprobs[someIndex])\n",
    "print(logprobs[someIndex, Yb[someIndex]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79d095-4ad6-4006-a90d-4b46398a5e01",
   "metadata": {},
   "source": [
    "dlogprobs will hold the derivative of the loss with respect to all the elements of logprobs. For this reason, it will also have the same shape as logprobs.\n",
    "\n",
    "Now how does logprobs influence the loss? Remember Yb is just an array of all the correct indices of the next character.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d846956-52ad-44b3-9a12-dbad3d6c893c",
   "metadata": {},
   "source": [
    "loss = -(a + b + c) / 3\n",
    "\n",
    "loss = -a/3 - b/3 - c/3\n",
    "\n",
    "So what is the derivative of the loss with respect to a?\n",
    "\n",
    "dloss/da = -1/3\n",
    "\n",
    "So the derivative is 1/n where n is the number of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe218cfb-a76a-42aa-bdfa-59f482e80021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddf765af-c32d-4390-8b8f-c1657900c083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogprobs[range(n), Yb] = -1.0/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64fbd8cd-cfbe-4fc0-b599-21b6c4cad124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "350f1dc2-3d59-4451-878e-21cf04e985d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs[someIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09c20150-0945-497d-958e-f8fbf82a7b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a344a4-e5e7-45d6-b6a9-96afd8315281",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### logprobs = probs.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f30da7-bc2e-42c8-861a-5dce39faadda",
   "metadata": {},
   "source": [
    "![](images/dxlogx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd72b4-259f-4c8a-b855-0a7f2894f9ba",
   "metadata": {},
   "source": [
    "In our example, x is probs, so the local derivate of probs.log() is simply (1.0 / probs).\n",
    "\n",
    "And because of the chain rule, we multiply that by dlogprobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76309828-0a1a-47f9-a1b2-7ec7a5dd3b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e67852-6ef1-4c35-8adb-15c1838aa383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634fef9-21d9-4fa5-8f03-d11dfcf8232d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### probs = counts * counts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "933d2df2-279a-49fb-8582-a8c6078a57fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "474a118b-145e-43fe-9407-76c959824568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = a * b, but with tensors:\n",
    "# a[3x3] * b[3x1] --->\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b3\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "# c[3x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cc98f46-7cd7-4275-8750-3e12a74a8a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9d1150c-f054-405a-b8a7-19b2f4f13d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e31fae5-439d-4bc2-ae3a-a9e941562e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts = (counts_sum_inv * dprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c32201-3046-4812-8118-7404289fc2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum_inv = counts_sum**-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb49f8-933c-4a1b-a5ce-a783cb5b04f3",
   "metadata": {},
   "source": [
    "![](images/ddx1_x.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a7dced4-4046-47a8-9e8a-b0b86596a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "989342ec-d642-4195-9039-88c3f5f5cd51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f2f1c-fb47-4974-9240-51caa7a89ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum = counts.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ee05909-e8b6-4b27-9bbc-5abfad5e365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add in the previous value we calculated for dcounts ... so use += \n",
    "dcounts += torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e8213d9-7ef1-4d1f-af5d-369850d3dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab2668-3a98-4490-97d2-832b90cd939d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts = norm_logits.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f3bae-039c-4dbc-92df-e9fe189ff15f",
   "metadata": {},
   "source": [
    "![](images/ddx_ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed793a-47bc-47b2-897a-808affc59dc6",
   "metadata": {},
   "source": [
    "The derivate of norm_logits.exp() is norm_logits.exp() which is already in counts, so let's just use counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e578f7e4-ed08-4e61-a3e5-2316add912c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnorm_logits = counts * dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be791f7b-2cb5-45c6-83a7-0f2d9f9c4221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37c448-9cd0-4efa-af85-2d21bc69974e",
   "metadata": {},
   "source": [
    "#### norm_logits = logits - logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a15e671-98f5-4d4d-8ba0-b248337d2085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapes are different ...\n",
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8293794a-149c-46af-85db-4c4f83a824b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c11 c12 c13 = a11 a12 a13 - b1\n",
    "# c21 c22 c23 = a21 a22 a23 - b2\n",
    "# c31 c32 c33 = a31 a32 a33 - b3\n",
    "\n",
    "# so e.g. c32 = a32 - b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5d0fc04-0de3-4972-88ef-c728b32ef037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogits = dnorm_logits.clone() # this is NOT our final derivative for dlogits!\n",
    "dlogit_maxes = (-dnorm_logits).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9f6b639-de88-4f71-876f-8c3ee4d3d9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828ba2-6f02-4c31-9d78-58f1572d9ac0",
   "metadata": {},
   "source": [
    "#### logit_maxes = logits.max(dim=1, keepdim=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "098cd840-f346-4696-810d-3b1621074016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice we use += because we need to add in the previous value\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1a52533-3bf3-4ec6-a0f3-219bf1c1bba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9aad439330>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6371c5f6-c236-4845-b472-a39065e5acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logits',dlogits,logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe3b59-0d27-4668-b77f-7c5a220510fa",
   "metadata": {},
   "source": [
    "#### logits = h @ W2 + b2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5692b264-a720-4368-add3-4b7ca084da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits.shape => torch.Size([32, 27])\n",
      "h.shape =======> torch.Size([32, 64])\n",
      "W2.shape ======> torch.Size([64, 27])\n",
      "(h@W2).shape ==> torch.Size([32, 27])\n",
      "b2.shape ======> torch.Size([27])\n"
     ]
    }
   ],
   "source": [
    "print(f'dlogits.shape => {dlogits.shape}')\n",
    "print(f'h.shape =======> {h.shape}')\n",
    "print(f'W2.shape ======> {W2.shape}')\n",
    "print(f'(h@W2).shape ==> {(h@W2).shape}')\n",
    "print(f'b2.shape ======> {b2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75b269df-700d-4551-a583-cb8aaef250d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dh must have the same shape as h 32x64\n",
    "dh = dlogits @ W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6ec24bf-74f7-4c2b-a4d0-1f623702a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dW2 must have the same shape as W2 64x27\n",
    "dW2 = h.T @ dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a253d2f4-2bef-46cd-9b29-f4c073b5220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db2 must have the same shape as b2 27\n",
    "db2 = dlogits.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff5db4c5-0685-41b0-8196-5111f4db537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate True  | maxdiff 0.0\n",
      "W2              | exact: True  | approximate True  | maxdiff 0.0\n",
      "b2              | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('h',dh,h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dbcae-b5fe-449a-a32f-066582eeb57f",
   "metadata": {},
   "source": [
    "#### h = torch.tanh(hpreact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158ccc5-b2ab-48ec-be5f-3667c9e6b754",
   "metadata": {},
   "source": [
    "![](images/ddx_tanh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17412276-878c-4395-ab28-2cd9e503eebd",
   "metadata": {},
   "source": [
    "Notice the derivate of tanh(z) is 1 - a**2, where a is the output of tanh, not the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a959826c-dc2b-4820-901b-f044eee731a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, the chain rule ... so multiply by dh\n",
    "dhpreact = (1.0 - h**2) * dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dde0baf9-0685-43fc-946c-0b1b9e97f2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# I think this is not exact just due to some rounding differences ... \n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "\n",
    "# We get this result ALMOST every time we restart the kernel and run all ...\n",
    "# hpreact         | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n",
    "\n",
    "# hmm other times we can get this ..\n",
    "# hpreact         | exact: False | approximate True  | maxdiff 9.313225746154785e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b732dc5e-30dc-420f-9b00-4689764b0257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(dhpreact == hpreact.grad).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01f068c1-bf5e-45d7-8e5f-971f0fc08dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(dhpreact, hpreact.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8dc6a2c9-162d-4fd8-9ff8-77532d1c79c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.656612873077393e-10"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dhpreact - hpreact.grad).abs().max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7341631b-c9a5-405e-a404-4b3e8c2a976b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -1.7462e-10, -5.8208e-11,  ...,  4.3656e-11,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  2.9104e-11,  ...,  0.0000e+00,\n",
       "          0.0000e+00, -2.3283e-10],\n",
       "        [ 0.0000e+00,  0.0000e+00, -8.7311e-11,  ...,  0.0000e+00,\n",
       "          2.9104e-11, -5.8208e-11],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  1.1642e-10],\n",
       "        [ 0.0000e+00,  7.2760e-12,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          5.8208e-11,  0.0000e+00],\n",
       "        [-5.4570e-12,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          5.8208e-11,  0.0000e+00]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dhpreact - hpreact.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a6dabfd-9094-4a2e-85bb-f938544879ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "not_equal = torch.not_equal(dhpreact, hpreact.grad)\n",
    "plt.imshow(not_equal, cmap='binary')\n",
    "plt.show()\n",
    "# white cells are equal ... why do we not see all white cells?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d881fa-c70a-4f8b-b828-df68ca6fe5a6",
   "metadata": {},
   "source": [
    "We now begin back propogation through the batch normalization layer. This is discussed in the paper \n",
    "\n",
    "[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b095f2e3-c9cf-4f3a-8744-0ddb0ed74eae",
   "metadata": {},
   "source": [
    "![](images/BatchNormalizationLayer.png)\n",
    "![](images/BatchNormalizingTransform.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af860b77-2731-468a-87e7-1379adbc6f17",
   "metadata": {},
   "source": [
    "#### hpreact = bngain * bnraw + bnbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0f5bf31-d55c-4b30-8635-0d1fbe6a964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact.shape => torch.Size([32, 64])\n",
      "bngain.shape => torch.Size([1, 64])\n",
      "bnraw.shape => torch.Size([32, 64])\n",
      "(bngain * bnraw).shape => torch.Size([32, 64])\n",
      "bnbias.shape => torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'hpreact.shape => {hpreact.shape}')\n",
    "print(f'bngain.shape => {bngain.shape}')\n",
    "print(f'bnraw.shape => {bnraw.shape}')\n",
    "print(f'(bngain * bnraw).shape => {(bngain*bnraw).shape}')\n",
    "print(f'bnbias.shape => {bnbias.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e1bf8a7-2fca-46cb-ad1d-55f7f80c6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbngain = (bnraw * dhpreact).sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85d51d28-9050-421f-a85f-5680b310acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnraw = (bngain * dhpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de9b2c7b-64e2-4a79-9b61-9c88ede166f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnbias = dhpreact.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c344b27a-9bfb-4d60-ab9b-8c9f5f04406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngain          | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n",
      "bnraw           | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n",
      "bnbias          | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba434b1-d388-4ca6-8f75-6f797cb0f702",
   "metadata": {},
   "source": [
    "#### bnraw = bndiff * bnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c34af17a-9e37-4776-80c3-73ec432ffa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff.shape => torch.Size([32, 64])\n",
      "bnvar_inv.shape => torch.Size([1, 64])\n",
      "(bndiff * bnvar_inv).shape => torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'bndiff.shape => {bndiff.shape}')\n",
    "print(f'bnvar_inv.shape => {bnvar_inv.shape}')\n",
    "print(f'(bndiff * bnvar_inv).shape => {((bndiff * bnvar_inv).shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81bb23cc-971f-4342-8ab4-216d624f8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff = bnvar_inv * dbnraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7f1ead6-d760-448d-bf95-173b3cc0ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: False | approximate False | maxdiff 0.0010679654078558087\n"
     ]
    }
   ],
   "source": [
    "cmp('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c62f58a1-e214-495f-98e1-cc0126aa552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar_inv = (bndiff * dbnraw).sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8730782d-7dec-43cd-9f61-a96ee94cbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar_inv       | exact: False | approximate True  | maxdiff 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71079ecb-2625-42ac-ba6a-8745c42ad428",
   "metadata": {},
   "source": [
    "#### bnvar_inv = (bnvar + 1e-5)**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0dc6e5be-3ef1-47ec-964b-b7ef04f0f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4dedefe6-0c64-4f30-95ef-9d427dfd36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('bnvar', dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de820967-5295-4a70-b159-87902edbe97a",
   "metadata": {},
   "source": [
    "#### bnvar = 1/(n-1) * (bndiff2).sum(dim=0, keepdim=True)\n",
    "\n",
    "[Bessel's Correction](https://mathcenter.oxford.emory.edu/site/math117/besselCorrection/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1a9b3bb-6893-4335-9c04-01b1b2364cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar.shape ===> torch.Size([1, 64])\n",
      "bndiff2.shape => torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'bnvar.shape ===> {bnvar.shape}')\n",
    "print(f'bndiff2.shape => {bndiff2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "40096ebb-9eae-47d9-896c-8daf41cc06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a11 a12\n",
    "# a21 a22\n",
    "# ----->\n",
    "# b1, b2, where:\n",
    "# b1 = 1/(n-1)*(a11 + a21)\n",
    "# b2 = 1/(n-1)*(a12 + a22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c3fccb6-df0e-478b-80db-5f6370a0c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16d6bc7a-f9a9-4ebc-a2e3-0bfd8c7eb2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff2         | exact: False | approximate True  | maxdiff 5.820766091346741e-11\n"
     ]
    }
   ],
   "source": [
    "cmp('bndiff2',dbndiff2, bndiff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69729b-d049-4c70-815e-48b8d127af28",
   "metadata": {},
   "source": [
    "#### bndiff2 = bndiff**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "846c1a4c-ba18-4d38-9e4b-ef9015e72647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7362b02b-e3b7-445d-9e5a-c556d1445dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we have to add in the previous calculation of bndiff with +=\n",
    "dbndiff += (2*bndiff) * dbndiff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cc4642fc-a3fd-4a8e-9042-3354f39c5457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "cmp('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0847ca9-867b-4b41-a8d7-16517ad82d88",
   "metadata": {},
   "source": [
    "#### bndiff = hprebn - bnmeani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef2f52bb-4f95-4d1a-a596-6129e42b0648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16319e4e-d0c7-4a3a-93a1-4bd71491a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn = dbndiff.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62509864-ae5b-41a0-a654-0c0c32eba47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate False | maxdiff 0.0010568175930529833\n"
     ]
    }
   ],
   "source": [
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f2b13f5-347d-4bf5-a4b3-0180c302f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnmeani = (-torch.ones_like(bndiff) * dbndiff).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49c60118-207d-4357-a396-dc5769154f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can actually just replace the above line with this ..\n",
    "# because ..\n",
    "# torch.ones_like(bndiff)\n",
    "# is just multiplying by 1 ... \n",
    "dbnmeani = (-dbndiff).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d8827de-058b-48a8-946b-06338bb389ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnmeani         | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('bnmeani', dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aae202-5c22-4f21-9de1-b40f51577558",
   "metadata": {},
   "source": [
    "#### bnmeani = 1/n * hprebn.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a4872e9-10d1-40ea-99fd-d8741d8067d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, we += this from the previous value ... \n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd5576b0-2abf-4106-b3ee-8776d68de7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08cbf0-1e70-4fbc-a586-6295a5b4c20e",
   "metadata": {},
   "source": [
    "So now we have finished back propagating through the batch normalization layer. We can now back propagate linear layer 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27653e-0330-4c72-87a8-c2772320093c",
   "metadata": {},
   "source": [
    "#### hprebn = embcat @ W1 + b1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92a9192d-a3d4-4f6c-8bd5-afde77201956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, embcat.shape, W1.shape, b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aca127eb-06fb-4c9a-a45b-7835687d2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40e7c413-b588-49a9-863e-85c5d6c8b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embcat          | exact: False | approximate True  | maxdiff 1.3969838619232178e-09\n",
      "W1              | exact: False | approximate True  | maxdiff 7.450580596923828e-09\n",
      "b1              | exact: False | approximate True  | maxdiff 4.190951585769653e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f43952-48ed-472c-8940-2f0f17b7a4a2",
   "metadata": {},
   "source": [
    "#### embcat = emb.view(emb.shape[0], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8942525-4b8e-410e-b589-7b90aca2386a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 3, 10]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embcat.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38f661b2-ad33-40f5-92b6-b728e4c67b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demb = dembcat.view(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17eed703-cb1d-488b-8c56-ef8928915fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: False | approximate True  | maxdiff 1.3969838619232178e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('emb', demb, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d25ff7-595e-4a09-af89-8d675082ae2a",
   "metadata": {},
   "source": [
    "#### emb = C[Xb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f56c9e2b-eb42-43ba-b435-494b7eae6841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10]) torch.Size([27, 10]) torch.Size([32, 3])\n",
      "tensor([[ 1,  1,  4],\n",
      "        [18, 14,  1],\n",
      "        [11,  5,  9],\n",
      "        [ 0,  0,  1],\n",
      "        [12, 15, 14]])\n"
     ]
    }
   ],
   "source": [
    "# forward pass: emb = C[Xb]\n",
    "print(emb.shape, C.shape, Xb.shape)\n",
    "print(Xb[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6db98868-2b54-4ecb-921d-72e8ae6ecedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = torch.zeros_like(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6eb5a21e-e5a1-451a-8972-e07a2d94946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "919df79b-7767-4943-89c0-a758aa3b0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: False | approximate True  | maxdiff 9.313225746154785e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8faa4a-90e6-4443-b381-75518ee0fb12",
   "metadata": {},
   "source": [
    "Run all the comparison statements together to get the overview of how we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1fe641d-6202-427f-ae5d-7793ff7e61bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate True  | maxdiff 0.0\n",
      "probs           | exact: True  | approximate True  | maxdiff 0.0\n",
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff 0.0\n",
      "counts_sum      | exact: True  | approximate True  | maxdiff 0.0\n",
      "counts          | exact: True  | approximate True  | maxdiff 0.0\n",
      "norm_logits     | exact: True  | approximate True  | maxdiff 0.0\n",
      "logit_maxes     | exact: True  | approximate True  | maxdiff 0.0\n",
      "logits          | exact: True  | approximate True  | maxdiff 0.0\n",
      "h               | exact: True  | approximate True  | maxdiff 0.0\n",
      "W2              | exact: True  | approximate True  | maxdiff 0.0\n",
      "b2              | exact: True  | approximate True  | maxdiff 0.0\n",
      "hpreact         | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n",
      "bngain          | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n",
      "bnbias          | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n",
      "bnraw           | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n",
      "bnvar_inv       | exact: False | approximate True  | maxdiff 7.450580596923828e-09\n",
      "bnvar           | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n",
      "bndiff2         | exact: False | approximate True  | maxdiff 5.820766091346741e-11\n",
      "bndiff          | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n",
      "bnmeani         | exact: False | approximate True  | maxdiff 1.862645149230957e-09\n",
      "hprebn          | exact: False | approximate True  | maxdiff 4.656612873077393e-10\n",
      "embcat          | exact: False | approximate True  | maxdiff 1.3969838619232178e-09\n",
      "W1              | exact: False | approximate True  | maxdiff 7.450580596923828e-09\n",
      "b1              | exact: False | approximate True  | maxdiff 4.190951585769653e-09\n",
      "emb             | exact: False | approximate True  | maxdiff 1.3969838619232178e-09\n",
      "C               | exact: False | approximate True  | maxdiff 9.313225746154785e-09\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5ce5941-d128-471c-bbdb-2481d325af77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.320523977279663 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c974dfc5-975e-40c5-88b5-d204d78eb9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate True  | maxdiff 9.313225746154785e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f78d9be2-c7d6-4a35-b1a8-f99defc978ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "16e9ab07-0826-47cb-a088-acb0106af4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0675, 0.0870, 0.0190, 0.0507, 0.0191, 0.0813, 0.0245, 0.0359, 0.0184,\n",
       "        0.0331, 0.0351, 0.0355, 0.0359, 0.0308, 0.0355, 0.0135, 0.0087, 0.0213,\n",
       "        0.0164, 0.0548, 0.0523, 0.0220, 0.0269, 0.0667, 0.0578, 0.0275, 0.0227],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d333e3c4-dc6a-440b-9a48-352924f2e34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0675,  0.0870,  0.0190,  0.0507,  0.0191,  0.0813,  0.0245,  0.0359,\n",
       "        -0.9816,  0.0331,  0.0351,  0.0355,  0.0359,  0.0308,  0.0355,  0.0135,\n",
       "         0.0087,  0.0213,  0.0164,  0.0548,  0.0523,  0.0220,  0.0269,  0.0667,\n",
       "         0.0578,  0.0275,  0.0227], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8852e9ef-22b2-4a69-affe-9867b1f4879d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3283e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "087eb1f9-7064-4835-b62f-3a0702793ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9aac3f7ca0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "26cf8e7d-740a-45bc-b538-c70adfd58f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1fd68be6-6855-4784-8829-67927b438f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate True  | maxdiff 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c6528a6e-2481-406d-819d-05e5156ad853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95d4b9df-0b0d-4508-bde9-322d1d1da0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7983\n",
      "  10000/ 200000: 2.1565\n",
      "  20000/ 200000: 2.3732\n",
      "  30000/ 200000: 2.4612\n",
      "  40000/ 200000: 1.9736\n",
      "  50000/ 200000: 2.3877\n",
      "  60000/ 200000: 2.3688\n",
      "  70000/ 200000: 2.0674\n",
      "  80000/ 200000: 2.3690\n",
      "  90000/ 200000: 2.1826\n",
      " 100000/ 200000: 2.0264\n",
      " 110000/ 200000: 2.2850\n",
      " 120000/ 200000: 2.0646\n",
      " 130000/ 200000: 2.4371\n",
      " 140000/ 200000: 2.3064\n",
      " 150000/ 200000: 2.1505\n",
      " 160000/ 200000: 2.0214\n",
      " 170000/ 200000: 1.8879\n",
      " 180000/ 200000: 1.9958\n",
      " 190000/ 200000: 1.8413\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda2642-c258-4f87-839e-14da12a6f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, try to run all the above on the GPU ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
