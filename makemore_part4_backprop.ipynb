{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7b64f-42fd-4a83-aefe-7d60678c3cf0",
   "metadata": {},
   "source": [
    "Tuesday, June 13, 2023\n",
    "\n",
    "This video shows how to manually implement back propogation in a multi layer perceptron.\n",
    "\n",
    "docker container start sad_nightingale\n",
    "\n",
    "[Building makemore Part 4: Becoming a Backprop Ninja](https://www.youtube.com/watch?v=q8SA3rM6ckI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25e9341-c435-4be5-ac56-0225357b4d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7c8aeb-0294-4ee3-b983-4e161201afb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "lenOfWords = len(words)\n",
    "print(lenOfWords)\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c51f71-77c2-40e7-a827-632a5947e89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3cd2a0-d8e2-4f08-8e00-efd0249d7552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8b147f-c618-47c6-b510-6ee2074aaf00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "stoi[delimiter] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b8f870-e3d5-44cd-a6b9-3f04b75252c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "itos = { c:i for i, c in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fcbb34-7767-4608-8ad7-b7fa04046c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1fed5e-846d-4f9e-af94-8f3a3d5881b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + delimiter:\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a6c897-d864-47ff-bde1-16df400e23ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thgttg = 42\n",
    "manualSeed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aafd307-ad2e-430a-8ad6-c37fff7f3ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(thgttg)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e6995a-ecec-4801-8344-b61f36463ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626 28829\n"
     ]
    }
   ],
   "source": [
    "n1 = int(0.8 * lenOfWords)\n",
    "n2 = int(0.9 * lenOfWords)\n",
    "print(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3ba7b7-0f67-42b0-ae1c-377507dc1dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Ytd = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a285df-b211-4b95-92eb-5cd2cb0f94a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ok boilerplate code is done, now we get to the action ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc684e22-ad13-4116-903e-5acebd5b65f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "all(input) -> Tensor\n",
       "\n",
       "Tests if all elements in :attr:`input` evaluate to `True`.\n",
       "\n",
       ".. note:: This function matches the behaviour of NumPy in returning\n",
       "          output of dtype `bool` for all supported dtypes except `uint8`.\n",
       "          For `uint8` the dtype of output is `uint8` itself.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(1, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[False, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a)\n",
       "    tensor(False, dtype=torch.bool)\n",
       "    >>> a = torch.arange(0, 3)\n",
       "    >>> a\n",
       "    tensor([0, 1, 2])\n",
       "    >>> torch.all(a)\n",
       "    tensor(False)\n",
       "\n",
       ".. function:: all(input, dim, keepdim=False, *, out=None) -> Tensor\n",
       "   :noindex:\n",
       "\n",
       "For each row of :attr:`input` in the given dimension :attr:`dim`,\n",
       "returns `True` if all elements in the row evaluate to `True` and `False` otherwise.\n",
       "\n",
       "If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
       "as :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
       "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
       "the output tensor having 1 fewer dimension than :attr:`input`.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    dim (int): the dimension to reduce.\n",
       "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(4, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[True, True],\n",
       "            [True, False],\n",
       "            [True, True],\n",
       "            [True, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=1)\n",
       "    tensor([ True, False,  True,  True], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=0)\n",
       "    tensor([ True, False], dtype=torch.bool)\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.all??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7c7971-604e-4dd2-a68b-a9d33b4ba034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> bool\n",
       "\n",
       "This function checks if all :attr:`input` and :attr:`other` satisfy the condition:\n",
       "\n",
       ".. math::\n",
       "    \\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n",
       "\n",
       "elementwise, for all elements of :attr:`input` and :attr:`other`. The behaviour of this function is analogous to\n",
       "`numpy.allclose <https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html>`_\n",
       "\n",
       "Args:\n",
       "    input (Tensor): first tensor to compare\n",
       "    other (Tensor): second tensor to compare\n",
       "    atol (float, optional): absolute tolerance. Default: 1e-08\n",
       "    rtol (float, optional): relative tolerance. Default: 1e-05\n",
       "    equal_nan (bool, optional): if ``True``, then two ``NaN`` s will be considered equal. Default: ``False``\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\n",
       "    True\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\n",
       "    True\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.allclose??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "547d57bd-92a1-4d3c-9bf5-b2c7669c81cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function we weill use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate {str(app):5s} | maxdiff {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52b92be0-1a5d-4719-b326-15e1fa06413c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(manualSeed) # for reproducability\n",
    "\n",
    "# the embedding table for the characters ...\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/ ((n_embd * block_size) ** 0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of batch normalization\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# Note: I am initializing many of these parameters in non-standard ways\n",
    "# because sometimes initializing with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd584d9-3904-4556-80fb-23f470f435d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a sorter variable, also for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86e31c48-7070-4f53-bf95-d76a0237d1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.sum??\n",
    "# Docstring:\n",
    "# sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
    "\n",
    "# See :func:`torch.sum`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee09c314-3285-496a-92a5-e8f5db1f84c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 2 + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc54fb01-8129-47a6-abba-7107f7ec0a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.max??\n",
    "# Docstring:\n",
    "# max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
    "\n",
    "# See :func:`torch.max`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a3feb65-ab62-4aec-9500-4516a28deb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3269, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# Batch Normalization Layer\n",
    "bnmeani = 1/n * hprebn.sum(dim=0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(dim=0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-Linearity\n",
    "h = torch.tanh(hpreact)\n",
    "\n",
    "# Linear Layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(dim=1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(dim=1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 # if we use (1.0 / counts_sum) instead then we can't get backprop to be bit exact ... \n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "    \n",
    "# PyTorch retain_grad => Enables this Tensor to have their grad populated during backward(). \n",
    "# This is a no-op for leaf tensors\n",
    "\n",
    "# afaik there is no cleaner way to do this ...\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "    norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "    bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "    embcat, emb]:\n",
    "    t.retain_grad()\n",
    "    \n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d276b27-73b1-4688-951d-06fdc144dba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Backprop through the whole thing manually, backpropagating through exactly all of the variables\n",
    "as they are defined in the forward pass above, one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9505f-7460-48b7-8cf6-a531916569d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad0fd759-092b-4ff9-82a3-b30639561473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "torch.Size([32])\n",
      "torch.Size([32, 27])\n",
      "torch.Size([32])\n",
      "tensor(3.3269, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "print(logprobs[range(n), Yb].shape)\n",
    "print(logprobs.shape)\n",
    "print(Yb.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "802e5b5e-0fd3-4e1a-b86d-fedfae7f033f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5593628-bf64-4da3-8b04-90d586a6812f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([-3.6804, -3.8018, -3.4160, -4.1942, -3.3732, -3.5036, -2.6600, -2.8418,\n",
      "        -3.4029, -3.4022, -3.4114, -3.0659, -2.8477, -2.9851, -4.1348, -3.7002,\n",
      "        -3.5675, -3.8965, -3.4717, -2.4440, -3.0686, -3.4112, -3.1687, -2.9879,\n",
      "        -3.4438, -3.8283, -3.7119], grad_fn=<SelectBackward0>)\n",
      "tensor(-3.4022, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "someIndex = 19\n",
    "print(Yb[someIndex].item())\n",
    "print(logprobs[someIndex])\n",
    "print(logprobs[someIndex, Yb[someIndex]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79d095-4ad6-4006-a90d-4b46398a5e01",
   "metadata": {},
   "source": [
    "dlogprobs will hold the derivative of the loss with respect to all the elements of logprobs. For this reason, it will also have the same shape as logprobs.\n",
    "\n",
    "Now how does logprobs influence the loss? Remember Yb is just an array of all the correct indices of the next character.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d846956-52ad-44b3-9a12-dbad3d6c893c",
   "metadata": {},
   "source": [
    "loss = -(a + b + c) / 3\n",
    "\n",
    "loss = -a/3 - b/3 - c/3\n",
    "\n",
    "So what is the derivative of the loss with respect to a?\n",
    "\n",
    "dloss/da = -1/3\n",
    "\n",
    "So the derivative is 1/n where n is the number of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe218cfb-a76a-42aa-bdfa-59f482e80021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf765af-c32d-4390-8b8f-c1657900c083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogprobs[range(n), Yb] = -1.0/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64fbd8cd-cfbe-4fc0-b599-21b6c4cad124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350f1dc2-3d59-4451-878e-21cf04e985d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs[someIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09c20150-0945-497d-958e-f8fbf82a7b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a344a4-e5e7-45d6-b6a9-96afd8315281",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### logprobs = probs.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f30da7-bc2e-42c8-861a-5dce39faadda",
   "metadata": {},
   "source": [
    "![](images/dxlogx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd72b4-259f-4c8a-b855-0a7f2894f9ba",
   "metadata": {},
   "source": [
    "In our example, x is probs, so the local derivate of probs.log() is simply (1.0 / probs).\n",
    "\n",
    "And because of the chain rule, we multiply that by dlogprobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76309828-0a1a-47f9-a1b2-7ec7a5dd3b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e67852-6ef1-4c35-8adb-15c1838aa383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634fef9-21d9-4fa5-8f03-d11dfcf8232d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### probs = counts * counts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "933d2df2-279a-49fb-8582-a8c6078a57fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "474a118b-145e-43fe-9407-76c959824568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = a * b, but with tensors:\n",
    "# a[3x3] * b[3x1] --->\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b3\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "# c[3x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cc98f46-7cd7-4275-8750-3e12a74a8a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9d1150c-f054-405a-b8a7-19b2f4f13d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e31fae5-439d-4bc2-ae3a-a9e941562e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts = (counts_sum_inv * dprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c32201-3046-4812-8118-7404289fc2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum_inv = counts_sum**-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb49f8-933c-4a1b-a5ce-a783cb5b04f3",
   "metadata": {},
   "source": [
    "![](images/ddx1_x.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a7dced4-4046-47a8-9e8a-b0b86596a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "989342ec-d642-4195-9039-88c3f5f5cd51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f2f1c-fb47-4974-9240-51caa7a89ff5",
   "metadata": {},
   "source": [
    "#### counts_sum = counts.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ee05909-e8b6-4b27-9bbc-5abfad5e365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add in the previous value we calculated for dcounts ... so use += \n",
    "dcounts += torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e8213d9-7ef1-4d1f-af5d-369850d3dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab2668-3a98-4490-97d2-832b90cd939d",
   "metadata": {},
   "source": [
    "#### counts = norm_logits.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f3bae-039c-4dbc-92df-e9fe189ff15f",
   "metadata": {},
   "source": [
    "![](images/ddx_ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed793a-47bc-47b2-897a-808affc59dc6",
   "metadata": {},
   "source": [
    "The derivate of norm_logits.exp() is norm_logits.exp() which is already in counts, so let's just use counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e578f7e4-ed08-4e61-a3e5-2316add912c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnorm_logits = counts * dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be791f7b-2cb5-45c6-83a7-0f2d9f9c4221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75b366-0a90-4414-b134-250c8cd735aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
