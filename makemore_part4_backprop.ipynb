{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7b64f-42fd-4a83-aefe-7d60678c3cf0",
   "metadata": {},
   "source": [
    "Tuesday, June 13, 2023\n",
    "\n",
    "This video shows how to manually implement back propogation in a multi layer perceptron.\n",
    "\n",
    "docker container start sad_nightingale\n",
    "\n",
    "[Building makemore Part 4: Becoming a Backprop Ninja](https://www.youtube.com/watch?v=q8SA3rM6ckI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25e9341-c435-4be5-ac56-0225357b4d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7c8aeb-0294-4ee3-b983-4e161201afb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "lenOfWords = len(words)\n",
    "print(lenOfWords)\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c51f71-77c2-40e7-a827-632a5947e89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3cd2a0-d8e2-4f08-8e00-efd0249d7552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8b147f-c618-47c6-b510-6ee2074aaf00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "stoi[delimiter] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b8f870-e3d5-44cd-a6b9-3f04b75252c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "itos = { c:i for i, c in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fcbb34-7767-4608-8ad7-b7fa04046c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1fed5e-846d-4f9e-af94-8f3a3d5881b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + delimiter:\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a6c897-d864-47ff-bde1-16df400e23ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thgttg = 42\n",
    "manualSeed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aafd307-ad2e-430a-8ad6-c37fff7f3ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(thgttg)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e6995a-ecec-4801-8344-b61f36463ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626 28829\n"
     ]
    }
   ],
   "source": [
    "n1 = int(0.8 * lenOfWords)\n",
    "n2 = int(0.9 * lenOfWords)\n",
    "print(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3ba7b7-0f67-42b0-ae1c-377507dc1dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Ytd = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a285df-b211-4b95-92eb-5cd2cb0f94a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ok boilerplate code is done, now we get to the action ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc684e22-ad13-4116-903e-5acebd5b65f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "all(input) -> Tensor\n",
       "\n",
       "Tests if all elements in :attr:`input` evaluate to `True`.\n",
       "\n",
       ".. note:: This function matches the behaviour of NumPy in returning\n",
       "          output of dtype `bool` for all supported dtypes except `uint8`.\n",
       "          For `uint8` the dtype of output is `uint8` itself.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(1, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[False, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a)\n",
       "    tensor(False, dtype=torch.bool)\n",
       "    >>> a = torch.arange(0, 3)\n",
       "    >>> a\n",
       "    tensor([0, 1, 2])\n",
       "    >>> torch.all(a)\n",
       "    tensor(False)\n",
       "\n",
       ".. function:: all(input, dim, keepdim=False, *, out=None) -> Tensor\n",
       "   :noindex:\n",
       "\n",
       "For each row of :attr:`input` in the given dimension :attr:`dim`,\n",
       "returns `True` if all elements in the row evaluate to `True` and `False` otherwise.\n",
       "\n",
       "If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
       "as :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
       "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
       "the output tensor having 1 fewer dimension than :attr:`input`.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    dim (int): the dimension to reduce.\n",
       "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.rand(4, 2).bool()\n",
       "    >>> a\n",
       "    tensor([[True, True],\n",
       "            [True, False],\n",
       "            [True, True],\n",
       "            [True, True]], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=1)\n",
       "    tensor([ True, False,  True,  True], dtype=torch.bool)\n",
       "    >>> torch.all(a, dim=0)\n",
       "    tensor([ True, False], dtype=torch.bool)\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.all??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7c7971-604e-4dd2-a68b-a9d33b4ba034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> bool\n",
       "\n",
       "This function checks if all :attr:`input` and :attr:`other` satisfy the condition:\n",
       "\n",
       ".. math::\n",
       "    \\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n",
       "\n",
       "elementwise, for all elements of :attr:`input` and :attr:`other`. The behaviour of this function is analogous to\n",
       "`numpy.allclose <https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html>`_\n",
       "\n",
       "Args:\n",
       "    input (Tensor): first tensor to compare\n",
       "    other (Tensor): second tensor to compare\n",
       "    atol (float, optional): absolute tolerance. Default: 1e-08\n",
       "    rtol (float, optional): relative tolerance. Default: 1e-05\n",
       "    equal_nan (bool, optional): if ``True``, then two ``NaN`` s will be considered equal. Default: ``False``\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\n",
       "    True\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\n",
       "    True\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.allclose??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "547d57bd-92a1-4d3c-9bf5-b2c7669c81cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function we weill use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate {str(app):5s} | maxdiff {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52b92be0-1a5d-4719-b326-15e1fa06413c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(manualSeed) # for reproducability\n",
    "\n",
    "# the embedding table for the characters ...\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/ ((n_embd * block_size) ** 0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of batch normalization\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# Note: I am initializing many of these parameters in non-standard ways\n",
    "# because sometimes initializing with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd584d9-3904-4556-80fb-23f470f435d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a sorter variable, also for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86e31c48-7070-4f53-bf95-d76a0237d1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.sum??\n",
    "# Docstring:\n",
    "# sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
    "\n",
    "# See :func:`torch.sum`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee09c314-3285-496a-92a5-e8f5db1f84c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 2 + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc54fb01-8129-47a6-abba-7107f7ec0a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.max??\n",
    "# Docstring:\n",
    "# max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
    "\n",
    "# See :func:`torch.max`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a3feb65-ab62-4aec-9500-4516a28deb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3380, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# Batch Normalization Layer\n",
    "bnmeani = 1/n * hprebn.sum(dim=0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(dim=0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-Linearity\n",
    "h = torch.tanh(hpreact)\n",
    "\n",
    "# Linear Layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(dim=1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(dim=1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 # if we use (1.0 / counts_sum) instead then we can't get backprop to be bit exact ... \n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "    \n",
    "# PyTorch retain_grad => Enables this Tensor to have their grad populated during backward(). \n",
    "# This is a no-op for leaf tensors\n",
    "\n",
    "# afaik there is no cleaner way to do this ...\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "    norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "    bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "    embcat, emb]:\n",
    "    t.retain_grad()\n",
    "    \n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d276b27-73b1-4688-951d-06fdc144dba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Backprop through the whole thing manually, backpropagating through exactly all of the variables\n",
    "as they are defined in the forward pass above, one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9505f-7460-48b7-8cf6-a531916569d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad0fd759-092b-4ff9-82a3-b30639561473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "torch.Size([32])\n",
      "torch.Size([32, 27])\n",
      "torch.Size([32])\n",
      "tensor(3.3380, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "print(logprobs[range(n), Yb].shape)\n",
    "print(logprobs.shape)\n",
    "print(Yb.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "802e5b5e-0fd3-4e1a-b86d-fedfae7f033f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5593628-bf64-4da3-8b04-90d586a6812f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([-3.7450, -3.8101, -3.4476, -4.1321, -3.2989, -3.3458, -2.7251, -3.0217,\n",
      "        -3.3737, -3.3711, -3.4646, -3.0926, -2.8165, -3.0468, -4.2681, -3.7560,\n",
      "        -3.5014, -3.9080, -3.4783, -2.3222, -3.0198, -3.3245, -3.2464, -3.0203,\n",
      "        -3.4667, -3.8504, -3.6574], grad_fn=<SelectBackward0>)\n",
      "tensor(-3.3711, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "someIndex = 19\n",
    "print(Yb[someIndex].item())\n",
    "print(logprobs[someIndex])\n",
    "print(logprobs[someIndex, Yb[someIndex]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79d095-4ad6-4006-a90d-4b46398a5e01",
   "metadata": {},
   "source": [
    "dlogprobs will hold the derivative of the loss with respect to all the elements of logprobs. For this reason, it will also have the same shape as logprobs.\n",
    "\n",
    "Now how does logprobs influence the loss? Remember Yb is just an array of all the correct indices of the next character.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d846956-52ad-44b3-9a12-dbad3d6c893c",
   "metadata": {},
   "source": [
    "loss = -(a + b + c) / 3\n",
    "\n",
    "loss = -a/3 - b/3 - c/3\n",
    "\n",
    "So what is the derivative of the loss with respect to a?\n",
    "\n",
    "dloss/da = -1/3\n",
    "\n",
    "So the derivative is 1/n where n is the number of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe218cfb-a76a-42aa-bdfa-59f482e80021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf765af-c32d-4390-8b8f-c1657900c083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogprobs[range(n), Yb] = -1.0/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64fbd8cd-cfbe-4fc0-b599-21b6c4cad124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350f1dc2-3d59-4451-878e-21cf04e985d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogprobs[someIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09c20150-0945-497d-958e-f8fbf82a7b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a344a4-e5e7-45d6-b6a9-96afd8315281",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### logprobs = probs.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f30da7-bc2e-42c8-861a-5dce39faadda",
   "metadata": {},
   "source": [
    "![](images/dxlogx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd72b4-259f-4c8a-b855-0a7f2894f9ba",
   "metadata": {},
   "source": [
    "In our example, x is probs, so the local derivate of probs.log() is simply (1.0 / probs).\n",
    "\n",
    "And because of the chain rule, we multiply that by dlogprobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76309828-0a1a-47f9-a1b2-7ec7a5dd3b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e67852-6ef1-4c35-8adb-15c1838aa383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634fef9-21d9-4fa5-8f03-d11dfcf8232d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### probs = counts * counts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "933d2df2-279a-49fb-8582-a8c6078a57fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "474a118b-145e-43fe-9407-76c959824568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = a * b, but with tensors:\n",
    "# a[3x3] * b[3x1] --->\n",
    "# a11*b1 a12*b1 a13*b1\n",
    "# a21*b2 a22*b2 a23*b3\n",
    "# a31*b3 a32*b3 a33*b3\n",
    "# c[3x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cc98f46-7cd7-4275-8750-3e12a74a8a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9d1150c-f054-405a-b8a7-19b2f4f13d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e31fae5-439d-4bc2-ae3a-a9e941562e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts = (counts_sum_inv * dprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c32201-3046-4812-8118-7404289fc2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum_inv = counts_sum**-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb49f8-933c-4a1b-a5ce-a783cb5b04f3",
   "metadata": {},
   "source": [
    "![](images/ddx1_x.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a7dced4-4046-47a8-9e8a-b0b86596a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "989342ec-d642-4195-9039-88c3f5f5cd51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f2f1c-fb47-4974-9240-51caa7a89ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts_sum = counts.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ee05909-e8b6-4b27-9bbc-5abfad5e365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add in the previous value we calculated for dcounts ... so use += \n",
    "dcounts += torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e8213d9-7ef1-4d1f-af5d-369850d3dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab2668-3a98-4490-97d2-832b90cd939d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### counts = norm_logits.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f3bae-039c-4dbc-92df-e9fe189ff15f",
   "metadata": {},
   "source": [
    "![](images/ddx_ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed793a-47bc-47b2-897a-808affc59dc6",
   "metadata": {},
   "source": [
    "The derivate of norm_logits.exp() is norm_logits.exp() which is already in counts, so let's just use counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e578f7e4-ed08-4e61-a3e5-2316add912c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnorm_logits = counts * dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be791f7b-2cb5-45c6-83a7-0f2d9f9c4221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37c448-9cd0-4efa-af85-2d21bc69974e",
   "metadata": {},
   "source": [
    "#### norm_logits = logits - logit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a15e671-98f5-4d4d-8ba0-b248337d2085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapes are different ...\n",
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8293794a-149c-46af-85db-4c4f83a824b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c11 c12 c13 = a11 a12 a13 - b1\n",
    "# c21 c22 c23 = a21 a22 a23 - b2\n",
    "# c31 c32 c33 = a31 a32 a33 - b3\n",
    "\n",
    "# so e.g. c32 = a32 - b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5d0fc04-0de3-4972-88ef-c728b32ef037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlogits = dnorm_logits.clone() # this is NOT our final derivative for dlogits!\n",
    "dlogit_maxes = (-dnorm_logits).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9f6b639-de88-4f71-876f-8c3ee4d3d9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828ba2-6f02-4c31-9d78-58f1572d9ac0",
   "metadata": {},
   "source": [
    "#### logit_maxes = logits.max(dim=1, keepdim=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "098cd840-f346-4696-810d-3b1621074016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice we use += because we need to add in the previous value\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1a52533-3bf3-4ec6-a0f3-219bf1c1bba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4e17835b40>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6371c5f6-c236-4845-b472-a39065e5acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('logits',dlogits,logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe3b59-0d27-4668-b77f-7c5a220510fa",
   "metadata": {},
   "source": [
    "#### logits = h @ W2 + b2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5692b264-a720-4368-add3-4b7ca084da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits.shape => torch.Size([32, 27])\n",
      "h.shape =======> torch.Size([32, 64])\n",
      "W2.shape ======> torch.Size([64, 27])\n",
      "h@W2).shape ===> torch.Size([32, 27])\n",
      "b2.shape ======> torch.Size([27])\n"
     ]
    }
   ],
   "source": [
    "print(f'dlogits.shape => {dlogits.shape}')\n",
    "print(f'h.shape =======> {h.shape}')\n",
    "print(f'W2.shape ======> {W2.shape}')\n",
    "print(f'h@W2).shape ===> {(h@W2).shape}')\n",
    "print(f'b2.shape ======> {b2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75b269df-700d-4551-a583-cb8aaef250d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dh must have the same shape as h 32x64\n",
    "dh = dlogits @ W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6ec24bf-74f7-4c2b-a4d0-1f623702a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dW2 must have the same shape as W2 64x27\n",
    "dW2 = h.T @ dlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a253d2f4-2bef-46cd-9b29-f4c073b5220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db2 must have the same shape as b2 27\n",
    "db2 = dlogits.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff5db4c5-0685-41b0-8196-5111f4db537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate True  | maxdiff 0.0\n",
      "W2              | exact: True  | approximate True  | maxdiff 0.0\n",
      "b2              | exact: True  | approximate True  | maxdiff 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('h',dh,h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c5721-ccc8-4056-80a6-5cdf31cda7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
