{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7b64f-42fd-4a83-aefe-7d60678c3cf0",
   "metadata": {},
   "source": [
    "Tuesday, June 13, 2023\n",
    "\n",
    "This video shows how to manually implement back propogation in a multi layer perceptron.\n",
    "\n",
    "docker container start sad_nightingale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25e9341-c435-4be5-ac56-0225357b4d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7c8aeb-0294-4ee3-b983-4e161201afb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "lenOfWords = len(words)\n",
    "print(lenOfWords)\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c51f71-77c2-40e7-a827-632a5947e89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3cd2a0-d8e2-4f08-8e00-efd0249d7552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8b147f-c618-47c6-b510-6ee2074aaf00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "stoi[delimiter] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b8f870-e3d5-44cd-a6b9-3f04b75252c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "itos = { c:i for i, c in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fcbb34-7767-4608-8ad7-b7fa04046c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1fed5e-846d-4f9e-af94-8f3a3d5881b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + delimiter:\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a6c897-d864-47ff-bde1-16df400e23ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thgttg = 42\n",
    "manualSeed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aafd307-ad2e-430a-8ad6-c37fff7f3ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(thgttg)\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e6995a-ecec-4801-8344-b61f36463ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626 28829\n"
     ]
    }
   ],
   "source": [
    "n1 = int(0.8 * lenOfWords)\n",
    "n2 = int(0.9 * lenOfWords)\n",
    "print(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3ba7b7-0f67-42b0-ae1c-377507dc1dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Ytd = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a285df-b211-4b95-92eb-5cd2cb0f94a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ok boilerplate code is done, now we get to the action ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547d57bd-92a1-4d3c-9bf5-b2c7669c81cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function we weill use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate {str(app):5s} | maxdiff {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b92be0-1a5d-4719-b326-15e1fa06413c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(manualSeed) # for reproducability\n",
    "\n",
    "# the embedding table for the characters ...\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/ ((n_embd * block_size) ** 0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of batch normalization\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# Note: I am initializing many of these parameters in non-standard ways\n",
    "# because sometimes initializing with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cd584d9-3904-4556-80fb-23f470f435d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a sorter variable, also for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e31c48-7070-4f53-bf95-d76a0237d1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.sum??\n",
    "# Docstring:\n",
    "# sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
    "\n",
    "# See :func:`torch.sum`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee09c314-3285-496a-92a5-e8f5db1f84c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * 2 + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc54fb01-8129-47a6-abba-7107f7ec0a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xb.max??\n",
    "# Docstring:\n",
    "# max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
    "\n",
    "# See :func:`torch.max`\n",
    "# Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a3feb65-ab62-4aec-9500-4516a28deb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3398, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# Batch Normalization Layer\n",
    "bnmeani = 1/n * hprebn.sum(dim=0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(dim=0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-Linearity\n",
    "h = torch.tanh(hpreact)\n",
    "\n",
    "# Linear Layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(dim=1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(dim=1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 # if we use (1.0 / counts_sum) instead then we can't get backprop to be bit exact ... \n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "# afaik there is no cleaner way to do this ...\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "    norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "    bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "    embcat, emb]:\n",
    "    t.retain_grad()\n",
    "    \n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50c79d-4b12-44fa-ba37-cbca0f6c0f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
